---
type: "post"
title: "机器学习课程学习笔记"
author: "horizon"
category: "Tech"
date: "2025-03-20"
slug: "/Tech_16"
postImage: "./img/Tech_16.jpg"
metaDescription: "记录了机器学习课程的学习笔记。包含了机器学习的基础知识、监督学习、无监督学习、强化学习、线性回归、决策树、随机森林、贝叶斯分类等内容。"
---

## 2.18 机器学习基础

1.  人工智能：能够处理⼀般需要⼈类知识和智⼒介⼊任务的计算机系统

    - 机器学习：从若⼲输⼊输出样例中学习数据规律的统计技术（机器学习是一类通过从数据中发掘潜在规律来不断优化自身性能，以实现特定目标的计算机算法。）
    - 深度学习：⼀种⾃动学习数据表征的机器学习技术

2.  传统编程：包含太多决策规则（比如关键词）

3.  机器学习的核心要素

    - 数据 (经验)
    - 模型 (假设)
    - 损失函数(目标)
    - 优化算法(提升)

4.  归根结底，机器学习是什么？

    - 定义：机器学习是一种人工智能技术，使机器能够在无需显式人工编程的情况下，通过从数据中自动发现潜在的统计规律（模型），并不断优化自身性能（优化），以实现特定的目标（如最小化损失函数）。

5.  推广到其他类型的数据

    - 向量化/特征提取(转化成高维向量空间中的点)

6.  以下人类学习行为分别对应哪种机器学习要素？

    1. 查文献 : 数据
    2. 考试 : 损失函数
    3. 错题总结 : 优化算法
    4. 挂科 : 没有

7.  如何构建一个机器学习系统？

    1. 考虑数据可⾏性和规模
       - 能获得多少数据? 需要多少代价 (时间、算⼒、⼈⼒成本)?
    2. 选择输⼊数据的合理表示形式
       - 数据预处理,特征提取,等等.
    3. 选择合理的模型假设
    4. 选择合适的损失函数
    5. 选择或设计⼀个学习算法

8.  机器学习分类

    - 监督学习：学习器的每个输入样本都有一个目标输出标签（有 “⽼师”的学习举例：老师教学生识别各种类型的动物。练习题提供标准答案）
      - 分类问题，回归问题
    - ⽆监督学习：Training examples as input patterns, with no associated output.
      - 聚类问题，降维问题，数据的概率密度估计，数据⽣成，异常检测
    - 强化学习：通过与环境交互来学习。学习状态(states)到动作(actions)的映射，以最大化长期奖励(reward)。（例: 练习题只给总分不给参考答案(刷题模式)）

9.  监督学习 vs.无监督学习

    - 监督学习
    - 数据:(x, y) x 表示数据,y 表示标签
    - 学习⽬标:学习函数映射 x →y
    - 典型任务:分类、回归、⽬标检测、语义分割等

    - 无监督学习
    - 数据:x 表示数据,⽆标签
    - 学习⽬标:学习数据隐含或潜在的结构
    - 典型任务:聚类、降维、概率密度估计等

10. 泛化性

    - 学习后的分类器能否处理没有见过的水果？
    - 学习的泛化性问题:模型应该学习普遍的规律还是记住特定细节?
    - 左边的模型更好，不复杂，泛化性更好

11. 欠拟合 vs 过拟合

    - 欠拟合–因模型不够复杂无法刻画真实规律，模型假设可能不成立
    - 过拟合–因模型过于复杂导致记住数据的细节(如随机噪声)而不是潜在的规律

## 2.25 机器学习基础

1. 避免过拟合（常见的避免过拟合方法）

   - 增加训练数据
   - 正则化(惩罚模型复杂度)
   - 数据划分&交叉验证(训练时用未知数据测试确保泛化能力)
   - 早停
   - 引入先验知识(如贝叶斯先验)

2. 措施一：数据划分

   - 模型拟合的是总体数据的分布而不仅仅是训练集的分布.
   - 为了评估泛化误差，需要在训练的时候保留一部分未知数据。
     - 数据划分(Hold-Out):
       - 训练集(e.g.,50%)
       - 验证集(e.g.,25%)
       - 测试集(e.g.,25%)

3. 措施二：交叉验证(CrossValidation)

   - 如何既划分数据，又能充分利用数据训练? (特别是当数据规模较⼩的时候)
   - K-折交叉验证
     - 将数据集分成 K 份
     - 依次将每份数据作为验证集，其余数据作为训练集
     - 计算 K 次验证结果的平均值

4. 措施三:早停(EarlyStop)

   - 在有过拟合迹象时及时停止训练

5. 措施四:正则化(Regularization)

   - 对参数增加惩罚项防止模型过拟合训练数据。
   - L1 正则化: $L1 = \lambda \sum_{i=1}^{n} |w_i|$
   - L2 正则化: $L2 = \lambda \sum_{i=1}^{n} w_i^2$

6. No free lunch 理论

   - 没有通用的最好的模型
   - 不同模型需要适配数据特征和应用

7. 机器学习中的回归问题

   - 回归问题:预测连续值

8. 线性回归

   - 使用一个线性函数来拟合数据
   - 损失函数:均方误差(Mean Squared Error)
     - $MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2$
   - 优化算法:梯度下降(Gradient Descent)
     - $w = w - \alpha \frac{\partial L}{\partial w}$

9. 线性回归的矩阵形式

   - 转化为矩阵求解问题

10. 正则化

    - 问题:XTX 可能不可逆
    - 解决方法:正则化(对损失函数引入一个惩罚项)
    - 对模型的惩罚变相地相当于数据的增强

## 2.28 决策树&随机森林&贝叶斯分类

1. 介绍了一下线性回归的具体算法实现

2. 然后讲了一下决策树模型

3. 回归 vs.分类

   - 回归:(predicts real-valued labels)
   - 分类:(predicts categorical labels)

4. 分类问题是机器学习处理的主要任务

5. 决策树和随机森林是最简单的分类算法

6. 分类=寻找一个决策边界，将特征空间划分成 2 个部分（每部分代表一个水果类型）

   - 非线性(cannotbelinearly separated)
   - 可能非数值 (e.g.,“male”, “female”)
   - 但是，沿着某些维度局部线性可分

7. 决策树的基本思想

   - 分而治之
   - 划分数据属性
   - 创建 if-then 规则

8. 决策树的模型结构,决策树包含三种类型的节点:

   1. 根节点(root node)
   2. 中间节点(Internal nodes)
   3. 叶子节点(Leaf nodes，terminal nodes)

   - 每个叶子节点对应一个类别标签
   - 每个非叶子节点包含属性测试条件， 用来根据属性不同特征划分数据.

9. 如何构建(训练)一棵决策树: 自顶向下分治学习

   1. 构造一个根节点，包含整个数据集.
   2. 选择一个最合适的属性
   3. 根据选择属性的不同取值，将当前节点的样本划分成若干子集；
   4. 对每个划分后的子集创建一个孩子节点，并将子集的数据传给该孩子节点；
   5. 递归重复 2~4 直到满足停止条件.

10. 如何高效率的构建决策树?

    - 选择每个属性 X 的时候，尽可能最大化标签 Y 的纯度
    - 决策树将数据逐步分割成越来越小的子集。最理想的情况是叶节点对应
      的样本属于同一类别(节点的标签纯净)。

11. 如何选择属性以最大化标签的纯度?

    - 选择 X 以最大化信息增益、Gini 系数等
    - 每⼀种指标对应⼀种决策树构造算法

12. 按照不同的属性划分原则，有以下常⻅算法：

    - ID3 (基于信息增益)
    - CART(基于 Gini Index)
    - C4.5 (基于信息增益率)

13. ID3 算法

    - 试着对每个属性进行划分，看看哪个划分效果“最好”
    - 评估样本的整体信息熵的降低程度
    - H(D) - H(D|X) = 信息增益 Gain(D, X)（即划分前后信息熵的差值）

14. 举例

    - Step1– 创建根节点
    - Step2– 计算每个(⼦)数据集的熵.
    - Step3– 对每个属性计算信息增益 IG,选择具有最⼤ IG 的属性
    - Step4–将最⼤ IG 的属性赋给当前(根)节点。对每个属性取值扩展⼀个分⽀⽤于创建新节点。
    - Step5–将数据集按选中的属性取值进⾏拆分，然后从数据集中移除该属性。
    - Step6–对每个划分后的⼦数据集，重复 2-5 步直到满⾜停⽌条件（递归）

15. 停止划分的条件

    - 纯度 – 叶⼦节点包含的样本均属于同⼀类
    - 数据量过小 – 叶⼦节点包含的样本数⼩于⼀个阈值
    - 没有属性可分(ID3)

16. 算法优点

    - 易理解, 可解释性, 便于可视化分析,
    - 数据预处理要求低,
    - 可以轻易处理非线性边界,
    - 数据驱动，可以以任意精度拟合训练集

17. 算法缺点

    - 容易过拟合
    - 某些噪声样例总能被树涵盖并学习

18. 随机森林

    - 将数据随机划分子集，各自构建决策树，将结果合并。
    - 优点：
    - 往往比决策树更准确（因为随机划分的时候、会把噪声给去掉）
    - 训练速度快, 容易并行化 (训练时树与树之间是相互独立的).
    - 可以处理高维(feature 很多)数据，并且不用做特征选择 (因为特征子集是随机选择的).
    - 可以处理缺失属性.
    - 结果易解释 (i.e.,在训练完后，能够给出哪些 feature 比较重要).
    - 在训练过程中，能够检测到 feature 间的互相影响。
    - 对于不平衡的数据集来说，它可以平衡误差。

19. 贝叶斯分类

    - 就是这两类数据不能用直接进行划分，但是符合一定的概率分布，然后通过概率分布来进行分类，刻画这个模型（比如正态分布）
    - 就是一开始、我们把这个数据认为是从线来产生的、然后现在把这个数据看作是投色子的概率来产生的
    - 参数就是 XY 的联合概率分布，然后通过这个联合概率分布来进行分类
    - 损失函数就是最大后验概率

## 3.4 朴素贝叶斯&KNN

1. 朴素贝叶斯分类（根据上面的概率思想、进行分类）

   - 一开始的场景是，我们分类邮件是否是垃圾邮件
   - P(C1) = 85%(是正常邮件的概率)(先验概率)
   - P(C2) = 15%(是垃圾邮件的概率)(先验概率)
   - X：邮件中的词（特征）（比如钱、免费、优惠）
   - P(X|Ci) :似然概率，即在某种邮件下，某个词出现的概率
   - P(Ci|X) :后验概率，即在某个词下，这个邮件是垃圾邮件的概率
   - Decision rule: decide C1 if p(x|C1)P(C1) > p(x|C2)P(C2)

2. 如果是多维的、就是多个特征、就是多个词，多个随机变量（但是也可以把它先看作是一个变量，然后通过联合概率进行计算，就是一个概率分布表，统计出来就可以做分类了）

   - 问题在于：这个联合概率分布表、太大了、过于复杂难以计算

3. 朴素贝叶斯假设

   - 在我某一个类已知的情况下、这些特征是相互独立的
   - 就不用把所有的概率都理一遍了
   - 即 P(X|Ci) = P(X1|Ci)P(X2|Ci)P(X3|Ci)P(X4|Ci)P(X5|Ci)

4. How to estimate each P(c)?

   - 直接统计每个类别的概率

5. How to estimate P(xi|c) for each c?

   - P(xi|c) = count(xi, c) / count(c)
   - count(xi, c) : 在类别 c 下，特征 xi 出现的次数
   - count(c) : 类别 c 出现的次数
   - 本质上就是数数

6. 但是有一个问题、有可能在训练集中、有些词在某个类别下没有出现、这个时候就会出现概率为 0 的情况（zero-count）

   - 解决方法：拉普拉斯平滑（即给每个 value 加一个 1）
   - P(xi|c) = (count(xi, c) + 1) / (count(c) + 1)

7. 应用场景

   - 文本分类（因为容易计数，每一个单次就是一个属性）
   - 实时预测（因为计算量小，快）
   - 多分类问题（因为类别的数量是可以指定为多个的）

8. 垃圾邮件里的例子

   - 先算似然概率和先验概率
   - 然后通过贝叶斯公式计算后验概率，然后比对后进行分类

9. 优点：

   - 训练和预测速度快
   - 多分类问题效果很好
   - 对缺失数据不太敏感，易于维护、可以很快地处理新数据（只需要增加或者删改计数）

10. 缺点：

    - 假设过于简单，会导致欠拟合（但是实际上的效果还是可以的）
    - 就是有时候词之间的出现也是有关系的、但是通过假设、就是没有考虑这个关系

11. 过程：朴素贝叶斯文本分类的流程分为三部分：输入是 m 个带人工标记类别的文档集合，每个文档由一组单词组成且对应一个类别标签；训练阶段先提取所有文档的词汇表，然后计算每个类别的概率 P(cj)（即该类文档数占总文档数的比例），再计算每个单词在特定类别下的条件概率 P(wk|cj)（用该词在该类文档中的出现次数加平滑系数 α，除以该类总词数加词汇表大小与 α 的乘积）；测试阶段对新文档的每个类别计算联合概率得分（该类的先验概率乘所有单词条件概率的乘积），最终输出得分最高的类别作为预测结果。

12. KNN：不需要模型的算法

    - 思想：物以类聚，人以群分
    - 算法：就是根据相邻的几个邻居做一个投票，然后根据投票结果进行分类
    - 问题：如何去度量这个距离

13. 欧氏距离的缺点：当维度变高的时候、受属性之间的区别关系就不大了

14. 实际数据分布的特点和缺点：

    - 就是在每个维度、数据的分布是不一样的，会导致在某些维度上、学习的效果不好
    - 解决方法：对每个维度进行归一化处理

15. 归一化方法：

    - 最大最小归一化：$x_{new} = \frac{x - min}{max - min}$
    - Z-score 标准化：$x_{new} = \frac{x - \mu}{\sigma}$

16. Similarity vs. Distance（相似度和距离）

    - 相似度：越大越相似
    - 距离：越小越相似

17. Cosine Similarity

    - 余弦相似度：$cos(\theta) = \frac{A \cdot B}{||A|| \cdot ||B||}$
    - 可以用来度量两个向量的相似度

18. 算法流程：

    - 决定 K
    - 计算测试样本和训练样本的距离
    - 选择距离最近的 K 个样本
    - 对这 K 个样本进行投票
    - 根据投票结果进行分类

19. 如何决定这个最好的 K 值？

    - 维诺图：就是 K 值和误差率的关系图（所有点之间等距离的边界）
    - K=1 的时候、就是垂直平分线
    - K>1 的时候、就是一个多边形，也会有很多空白区域（就是离邻居的距离都是相等的区域）
    - K 比较小的时候、分离面会比较小、过拟合
    - K 比较大的时候、分离面会比较光滑、会比较自然（ppt 上有图）

20. 如何选取 k

    - 如果 k 太小了、那么虽然效率高，但是容易受到噪声的影响
    - 大的 k 还不错、但是如果太大了、会导致过拟合、边缘平滑（因为会考虑到太多其他类的点）

21. 优点：

    - 简单、易于理解
    - 无需训练
    - 新的数据很容易被加入

22. 缺点：

    - 计算量大
    - 高度数据相关
    - 需要大量的内存
    - 需要正则化处理

## 3.11 逻辑斯蒂回归

1. 决策树：构造决策面

2. 朴素贝叶斯：基于数据的概率分布

3. KNN：基于距离的分类找决策面

4. 上面方法的共性：找决策面

5. 把所有决策交给数据：抛开决策面和几何意义（逻辑斯蒂回归，利用数学函数进行投票统计）

6. 判别函数：用来将数据分开（可以是概率密度、也可以不是、只要能分开就可以了）

7. 决策边界：就是判别函数的值为 0 的地方

8. 判别函数：首先想到线性函数

   - 好处：简单、易于理解、可解释、准确
   - 几何意义：就是一个分离的超平面（半平面）
   - 由此便诞生了感知机

9. 感知机：就是一个最简单的线性分类器

   - 按照数据在超平面的哪一边来进行分类
   - 训练：如果预测出错，则更新权重（移动超平面进行修正）
   - 缺点：因为这个函数是阶跃的 01 函数，所以难以进行优化
   - 因此引入了刻画这个数据属于哪一类的程度（概率）

10. 为了体现 y 和 1-y 之间的关系，对 y/(1-y)取了 log、并与 0 对比

    - 即为 logit 函数：$logit(p) = log(\frac{p}{1-p})$
    - 可验证即相当于线性的

11. sigmoid 函数：logit 函数的反函数

    - $sigmoid(x) = \frac{1}{1+e^{-x}}$
    - 作用：将线性函数的输出映射到 0-1 之间
    - 完美的概率拟合公式

12. 逻辑斯蒂回归

    - 使用了 sigmoid 函数的分类器
    - 根据预测出的概率值进行分类

13. 损失函数设计

    - 要最大化 log p 的值
    - 因为当 r=1 时候、cost=-log(y)、当 r=0 时候、cost=-log(1-y)
    - 因此使用交叉熵损失函数：$L(y, \hat{y}) = -ylog(\hat{y}) - (1-y)log(1-\hat{y})$
    - 也相当于要最大化似然函数

14. 优化方法：梯度下降

    - 求导：$\frac{\partial L}{\partial w} = (y-\hat{y})x$
    - 更新：$w = w + \alpha(y-\hat{y})x$
    - 不断优化损失函数

15. 多分类的时候，对函数进行了扩展

    - softmax 函数：$softmax(x) = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}$
    - 作用：将线性函数的输出映射到 0-1 之间
    - 每个输入称为 logits
    - 最终得到所有类下的概率分布
    - soft：函数可微
    - max：选择最大的数值（原来是不可微的，离散的，softmax 把它变成了可微的）

16. softmax 里面、标签是一个向量、预测值也是一个向量

## 3.14 SVM 支持向量机

1. 最简单的线性分类器：感知机（通过函数的统一化思想）

2. 逻辑斯蒂回归：（概率）进行分类

3. 前言：线性分类：可能会有很多根线、要找到更好的那根分割线（横着还是竖着）

   - 应该选择把两边的间距最大化的那根线（因为这样可以更好的泛化）

4. 数学推导：要把那个小 δ 消去，相当于把两个平面加起来，然后这两个平面加起来之后、就是原来分割的超平面（w 是未知量、是要学习的变量）

   - 可以把那个小 δ 令为+1 和 -1，然后就可以得到一个等式
   - margin = 2/||w||
   - 优化目标：最大化 margin
   - 最后要最大化这个 margin 等效于要最小化 1/2 的 ||w||（||w||是 w 的范数，即 w 的长度）
   - 第二个约束：要在两个超平面外的至少距离为 1

5. 支持向量机：

   - 即一个凸优化问题（二次优化问题）
   - minimize $\frac{1}{2}||w||^2$
   - subject to $y_i(w \cdot x_i + b) \geq 1$
   - 结构：还是一个感知机
   - 区别：损失函数变化了

6. 损失函数：

   - hinge loss：$L(y, \hat{y}) = max(0, 1-y\hat{y})$
   - 作用：当预测正确的时候、损失为 0(因为已经满足了)，当预测错误的时候、损失为 1-y\hat{y}（相当于关注线和边界上的点）
   - 核心思想是：不仅要求分类正确，还要确保分类的置信度足够高 ​（即远离决策边界）。
   - 只有那些位于间隔内（yi​⋅f(xi )<1）或分类错误的样本才会贡献损失，这些样本称为支持向量。
   - 优点：对异常值不敏感

7. 支持向量机（SVM）是一种监督学习算法，主要用于分类和回归任务。其核心思想是找到一个最优超平面（或决策边界），最大化不同类别数据之间的间隔（**间隔最大化**）。以下是 SVM 的原理和核函数作用的详细说明，以及核函数的例子：

---

### **1. SVM 的核心原理**

- **线性可分情况**：  
  当数据线性可分时，SVM 通过寻找一个超平面 \( \mathbf{w}^T \mathbf{x} + b = 0 \)，使得两类样本到超平面的最小距离（即间隔，margin）最大。优化目标是：
  \[
  \min\_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2 \quad \text{s.t.} \quad y_i (\mathbf{w}^T \mathbf{x}\_i + b) \geq 1, \forall i
  \]
  其中 \( y_i \in \{-1, 1\} \) 是类别标签。

- **非线性可分情况**：  
  当数据线性不可分时，SVM 引入**松弛变量**（slack variables）允许部分样本违反约束，转化为软间隔优化问题：
  \[
  \min*{\mathbf{w}, b, \xi} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum*{i} \xi_i \quad \text{s.t.} \quad y_i (\mathbf{w}^T \mathbf{x}\_i + b) \geq 1 - \xi_i, \xi_i \geq 0
  \]
  \( C \) 是惩罚参数，控制分类错误的容忍度。

---

### **2. 核函数的作用**

- **升维映射**：  
  对于非线性问题，SVM 通过核函数 \( K(\mathbf{x}\_i, \mathbf{x}\_j) \) 将原始数据映射到高维空间（如无限维的希尔伯特空间），使得在高维空间中线性可分。核函数避免了显式计算高维映射 \( \phi(\mathbf{x}) \)，直接通过内积操作降低计算复杂度（**核技巧**）。

- **核心优势**：
  - 无需知道 \( \phi(\mathbf{x}) \) 的具体形式。
  - 解决非线性分类问题，同时保持计算效率。

---

### **3. 常见核函数示例**

| 核函数名称        | 公式                                                                                       | 特点与应用场景                                             |
| ----------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------- |
| **线性核**        | \( K(\mathbf{x}\_i, \mathbf{x}\_j) = \mathbf{x}\_i^T \mathbf{x}\_j \)                      | 适用于线性可分数据，计算高效。                             |
| **多项式核**      | \( K(\mathbf{x}\_i, \mathbf{x}\_j) = (\gamma \mathbf{x}\_i^T \mathbf{x}\_j + r)^d \)       | 通过阶数 \( d \) 控制复杂度，适合中等非线性问题。          |
| **高斯核（RBF）** | \( K(\mathbf{x}\_i, \mathbf{x}\_j) = \exp(-\gamma \|\mathbf{x}\_i - \mathbf{x}\_j\|^2) \)  | 最常用，通过 \( \gamma \) 控制灵活性，适合复杂非线性边界。 |
| **Sigmoid 核**    | \( K(\mathbf{x}\_i, \mathbf{x}\_j) = \tanh(\gamma \mathbf{x}\_i^T \mathbf{x}\_j + r) \)    | 类似神经网络激活函数，但可能非正定。                       |
| **拉普拉斯核**    | \( K(\mathbf{x}\_i, \mathbf{x}\_j) = \exp(-\gamma \|\mathbf{x}\_i - \mathbf{x}\_j\|\_1) \) | 对噪声更鲁棒，稀疏特征适用。                               |

---

### **4. 核函数的选择建议**

- **RBF 核**通常是首选，尤其当数据分布未知时。
- **线性核**适合特征维度高、样本量大的场景（如文本分类）。
- **多项式核**需调参 \( d \) 和 \( \gamma \)，可能过拟合。
- 实际应用中，可通过交叉验证选择最优核函数和超参数（如 \( C \)、\( \gamma \)）。

---

### **5. 数学直观解释**

核函数本质是衡量样本相似性的函数。例如，RBF 核的值随样本距离增大而指数衰减，相似样本的核值接近 1，不相似的接近 0。SVM 通过核矩阵（Gram 矩阵）将原始问题转化为对偶问题求解：
\[
\max*{\alpha} \sum*{i} \alpha*i - \frac{1}{2} \sum*{i,j} \alpha_i \alpha_j y_i y_j K(\mathbf{x}\_i, \mathbf{x}\_j)
\]
其中 \( \alpha_i \) 是拉格朗日乘子，非零 \( \alpha_i \) 对应的样本即**支持向量**。

---

通过核函数，SVM 能够灵活处理从简单线性到高度非线性的分类问题，成为机器学习中的经典算法。

根据您提供的图片内容，图中描述的是**基于梯度下降的 SVM 训练算法**（针对线性可分或软间隔问题）。以下是该算法的简明步骤总结：

---

### **梯度下降法训练 SVM 的算法过程**

1. **输入与初始化**

   - 输入数据集 \( D = \{(x^{(\ell)}, y^{(\ell)})\}\_{\ell=1}^N \)，其中 \( y^{(\ell)} \in \{-1, 1\} \)。
   - 初始化权重 \( w_j \)（包括偏置 \( w_0 \)）为 \( [-0.01, 0.01] \) 范围内的随机数。

2. **迭代优化**（外层循环）  
   重复以下步骤直至收敛：

   - **遍历样本**（内层循环）：  
     对每个样本 \( (x^{(\ell)}, y^{(\ell)}) \)：
     1. 计算激活值 \( a \)：  
        \[ a = \sum\_{j=0}^d w_j x_j^{(\ell)} \quad (x_0^{(\ell)}=1 \text{，对应偏置项}) \]
     2. 计算梯度更新量 \( \Delta w_j \)：
        - 正则化项梯度：\( \Delta w_j \leftarrow \lambda w_j \)（\( \lambda \) 控制正则化强度）。
        - 若样本分类错误（\( y^{(\ell)} a < 1 \)），追加损失函数梯度：  
          \[ \Delta w_j \leftarrow \Delta w_j - y^{(\ell)} x_j^{(\ell)} \]  
          \[ \Delta w_0 \leftarrow \Delta w_0 - y^{(\ell)} \quad (\text{偏置项单独处理}) \]
     3. **更新权重**：  
        \[ w_j \leftarrow w_j - \eta \Delta w_j \]  
        （\( \eta \) 为学习率，控制步长）

3. **终止条件**
   - 当权重变化小于阈值或达到最大迭代次数时停止。

---

### **关键点说明**

- **目标函数**：算法隐式优化软间隔 SVM 的合页损失（Hinge Loss） + L2 正则化：  
  \[ \min*w \frac{\lambda}{2} \|w\|^2 + \sum*{\ell} \max(0, 1 - y^{(\ell)}(w^T x^{(\ell)})) \]
- **分类决策**：训练完成后，预测时计算 \( \text{sign}(w^T x + w_0) \)。
- **与核方法的联系**：若需处理非线性问题，需将内积 \( x_i^T x_j \) 替换为核函数 \( K(x_i, x_j) \)，但图中未体现此步骤。

---

### **对比经典 SVM 求解**

- 图中方法使用梯度下降，适合大规模数据；
- 传统 SVM 通常通过求解对偶问题（二次规划）获得支持向量，更精确但计算复杂度高。

如果需要进一步解释其他 SVM 变体（如核函数、对偶形式），可以补充说明。

## 3.18 MLP 多层感知机

1. 根据人脑的神经元模型、提出了神经网络

2. 感知机：

   - 一个输入函数
   - 一个激活函数
   - 一个损失函数
   - 可以看作一个最简单的线性模型

#### **1. 输入函数（Input Function）**

**作用**：线性加权求和，将输入特征组合成决策边界。  
**数学形式**：  
\[
z = w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + b = \mathbf{w}^T \mathbf{x} + b  
\]

- \( \mathbf{w} \)：权重向量，决定各特征的重要性。
- \( b \)：偏置项，控制决策边界的偏移。
- **物理意义**：生成一个超平面，用于划分数据空间（如二维中的直线）。

---

#### **2. 激活函数（Activation Function）**

**作用**：将线性输出 \( z \) 转换为离散的类别预测（二分类）。  
**常用函数**：**阶跃函数（Step Function）**  
\[
f(z) =
\begin{cases}
1 & \text{if } z \geq 0, \\
-1 \text{（或 } 0\text{）} & \text{if } z < 0.
\end{cases}
\]

- **关键特性**：非线性、输出离散值（如 ±1 或 0/1）。
- **意义**：将连续输入映射为明确的类别标签，实现分类决策。

---

#### **3. 损失函数（Loss Function）**

**作用**：量化预测错误程度，指导模型参数更新。  
**常用函数**：**感知机损失（Perceptron Loss）**  
\[
L(\mathbf{w}, b) = \sum\_{(\mathbf{x}\_i, y_i) \in \text{误分类点}} -y_i (\mathbf{w}^T \mathbf{x}\_i + b)  
\]

- **特点**：仅对误分类点计算损失（正确分类时损失为 0）。
- **优化目标**：最小化误分类样本到决策边界的距离（即 \( -y_i z \)）。

3. 感知机最基本的作用：分类，逻辑运算（但是单个感知机没法解决异或问题）

4. 转折：但是隐藏层的加入、可以解决异或问题（即非线性问题，通过含隐藏层的多层感知机进行解决）

5. 还有一个问题：原来的 01 激活函数太简单的、不能进行优化，因此引入了 sigmoid 函数（连续的、可微的）

6. 三层：

   - 输入层：输入数据
   - 隐藏层：给数据进行初步的线性转换和非线性的激活（通过 sigmoid），然后告诉下一层
   - 输出层：把小的感知机的结果进行汇总

7. 多层感知机：万能的拟合工具（可以拟合很多非线性函数）

   - MLP 也叫 Fully Connected Neural Network

8. MLP 在干啥：

   - 狗的例子：第一层、先在图片里面找最基本的特征（比如有没有三角形、有没有轮廓），然后在后面层判断进一步细致的特征（比如是不是有两个眼睛）
   - 非线性变换的例子：相当于线性变换（旋转等）和非线性变换（拉伸和拟合）的组合，对一个空间进行一个揉捏

9. MLP 的相较于决策树的优势：MLP 是连续可微的，而决策树涉及离散的分裂点选择，不连续可微。连续可微带来的优势，可使用梯度下降优化，适用于端到端学习。决策树的优势：可解释性强，处理非线性边界，不需要特征缩放（对数据尺度不敏感），​ 训练速度快

10. MLP 中如何训练？学习的参数是巨大的

    - 但是本质上：还是要算梯度

11. 损失函数（需要最小化）：

    - MSE：$L(y, \hat{y}) = \frac{1}{2}(y-\hat{y})^2$

12. 通过导数的链式规则、推导得出了可以通过反向传播的方法、来进行参数的更新

    - 反向传播：就是通过链式法则、把损失函数的导数传递到每一层（得到结果之后、然后再反向传播）

13. 前向传播：

    - 从输入层到输出层的过程

14. 所以反向传播里有两个步骤，分别为正向和反向，然后合并起来就是梯度

    - 正向（forward pass）：计算 δa/δw
    - 反向（backward pass）：计算 δL/δa
    - 乘积：δL/δw（即梯度）

## 3.25 MLP 多层感知机 & Language Model

1. 问题：反向传播中使用递归的方式、会导致计算量巨大

   - 解决方法：使用动态规划的方式、把计算结果存储起来
   - a：就是激活函数的输入
   - w：就是权重
   - L：就是损失函数

2. 因此：权重的更新就是输入信号和误差信号的乘积

   - 输入信号：δa/δw
   - 误差信号：δL/δa

3. 算法过程总结

   - 正向传播：计算每一层的 δa/δw
   - 反向传播：计算每一层的 δL/δa
   - 更新权重：根据梯度更新权重

4. ppt 上有一个显示的流程

5. 为什么越深的神经网络越好呢？

   - 因为可以做模块化的学习（比如第一层学习轮廓、第二层学习眼睛等）
   - 而且不要想着一次性规划所有的任务
   - 这样模块化的分类可以使用更少的数据进行训练

6. 过深的神经网络的缺陷

   - 难以训练（梯度消失和梯度爆炸）
   - 过拟合（因为参数太多了）
   - 很多局部最优解（因为参数太多了）

7. 深度学习 deep learning

   - 通过数据，学习高层次的抽象
   - 通过多层次的特征提取，学习数据的高层次表示

8. 深度学习的表征：

   - 传统的：通过人工和专家知识来设计特征
   - 深度学习：通过数据来学习特征（通过训练学出来的特征）
   - 同时，深度学习学到的是层次化的特征（把数据逐层地去抽象）
   - 深度学习把原有的机器学习的特征提取和分类的过程合并到了一起（用一个黑盒）
   - 因为数据变多了、所以深度学习的效果会更好

9. Feedforward Deep Neural Network（前馈深度神经网络），也称为多层感知机（MLP）​，是一种经典的深度学习模型。它由多个全连接层（Fully Connected Layers）堆叠而成，数据从输入层单向传递到输出层，没有循环或跳跃连接。以下是其核心概念和特点：

10. 缺点：原有的 Feedforward DNN 非常难以训练

11. 以下是 **深度学习（Deep Learning, DL）、机器学习（Machine Learning, ML）和强化学习（Reinforcement Learning, RL）** 的对比表格，涵盖核心差异、典型算法和应用场景：

| **对比维度**   | **机器学习（ML）**                    | **深度学习（DL）**                              | **强化学习（RL）**                                 |
| -------------- | ------------------------------------- | ----------------------------------------------- | -------------------------------------------------- |
| **核心思想**   | 从数据中学习模式，完成预测或分类。    | 通过多层神经网络自动提取高阶特征。              | 智能体通过与环境交互学习最优策略，最大化累积奖励。 |
| **数据依赖**   | 适用于中小规模数据。                  | 依赖大规模数据（如百万级样本）。                | 需要大量交互数据（如游戏中的试错）。               |
| **特征工程**   | 需人工设计特征（如 SVM 的特征选择）。 | 自动学习特征（如 CNN 提取图像边缘、纹理）。     | 无需显式特征工程，但需设计奖励函数。               |
| **典型算法**   | - 决策树<br>- SVM<br>- 随机森林       | - CNN（图像）<br>- RNN（序列）<br>- Transformer | - Q-Learning<br>- DQN<br>- PPO                     |
| **模型复杂度** | 相对简单，可解释性强。                | 高度复杂（百万至数十亿参数），黑盒性强。        | 中等复杂度，依赖环境建模。                         |
| **训练方式**   | 监督/无监督学习（静态数据集）。       | 监督/无监督/自监督学习（静态数据集）。          | 动态环境中的试错学习（在线或模拟环境）。           |
| **优化目标**   | 最小化预测误差（如交叉熵、MSE）。     | 最小化损失函数（如交叉熵、对比损失）。          | 最大化长期累积奖励（如游戏得分）。                 |
| **计算资源**   | CPU 或低配 GPU 即可训练。             | 需高性能 GPU/TPU（如训练 ResNet）。             | 需模拟环境或分布式计算（如 AlphaGo）。             |
| **应用场景**   | - 房价预测<br>- 信用评分              | - 图像识别<br>- 机器翻译<br>- 语音合成          | - 游戏 AI<br>- 机器人控制<br>- 自动驾驶            |
| **优缺点**     | ✅ 可解释性强<br>❌ 依赖特征工程      | ✅ 自动特征提取<br>❌ 数据/算力需求高           | ✅ 适应动态环境<br>❌ 训练不稳定、奖励难设计       |
| **代表案例**   | 垃圾邮件过滤（SVM）                   | ChatGPT（Transformer）                          | AlphaGo（DQN + 蒙特卡洛树搜索）                    |

### **训练 MLP（多层感知机）的步骤简述**

#### **1. 初始化网络结构**

- **定义层数**：
  - 输入层（节点数 = 特征维度）、若干隐藏层（每层节点数需指定）、输出层（节点数 = 类别数/回归值）。
- **初始化权重**：
  - 权重矩阵 \( W \) 和偏置 \( b \) 随机初始化（如 Xavier/Glorot 初始化）。

#### **2. 前向传播（Forward Pass）**

- **计算每层输出**：
  - 输入数据 \( X \) 经过线性变换 + 激活函数逐层传递：  
    \[
    z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]}, \quad a^{[l]} = \sigma(z^{[l]})
    \]
  - 常用激活函数 \( \sigma \)：ReLU（隐藏层）、Sigmoid/Softmax（输出层）。
- **最终输出**：
  - 输出层结果 \( \hat{y} = a^{[L]} \)（如分类概率或回归值）。

#### **3. 计算损失（Loss）**

- **选择损失函数**：
  - 分类任务：交叉熵损失 \( L = -\sum y \log(\hat{y}) \)。
  - 回归任务：均方误差 \( L = \frac{1}{N} \sum (y - \hat{y})^2 \)。

#### **4. 反向传播（Backpropagation）**

- **计算梯度**：
  - 从输出层反向逐层求导，链式法则计算损失对权重 \( W^{[l]} \) 和偏置 \( b^{[l]} \) 的梯度：  
    \[
    \frac{\partial L}{\partial W^{[l]}} = \frac{\partial L}{\partial z^{[l]}} a^{[l-1]T}, \quad \frac{\partial L}{\partial b^{[l]}} = \frac{\partial L}{\partial z^{[l]}}
    \]
  - 激活函数导数需参与计算（如 ReLU 的导数为 0 或 1）。

#### **5. 参数更新**

- **梯度下降优化**：
  - 使用优化器（如 SGD、Adam）更新参数：  
    \[
    W^{[l]} \leftarrow W^{[l]} - \eta \frac{\partial L}{\partial W^{[l]}}, \quad b^{[l]} \leftarrow b^{[l]} - \eta \frac{\partial L}{\partial b^{[l]}}
    \]
  - \( \eta \) 为学习率，控制更新步长。

#### **6. 迭代训练**

- **重复步骤 2~5**：
  - 遍历所有训练数据（一个 epoch），多次迭代直至收敛或达到最大 epoch 数。
- **验证与早停**：
  - 监控验证集性能，使用早停（Early Stopping）防止过拟合。

#### **7. 预测（Inference）**

- 前向传播新数据 \( X\_{\text{test}} \)，输出预测结果 \( \hat{y} \)。

---

### **关键点总结**

- **可微性核心**：前向传播（线性+激活）和反向传播（梯度计算）依赖所有运算可微。
- **与决策树对比**：  
  | **训练特性** | MLP | 决策树 |  
  |-------------------|-----------------------------|---------------------------|  
  | **优化方法** | 梯度下降（可微优化） | 贪心算法（不可微） |  
  | **计算效率** | 慢（需迭代） | 快（单次分裂） |  
  | **适用数据** | 连续数据（需标准化） | 离散/连续数据（无需标准化） |

通过可微的端到端训练，MLP 能够学习复杂非线性模式，但需注意超参数调优（如学习率、隐藏层大小）和正则化（如 Dropout、L2）。

9. MSE 直接衡量预测值与真实值的距离。MSE 对大误差 ​（异常值）惩罚更重（平方放大效应），这在某些场景下是优点（强调精确拟合）

**Sigmoid 函数**及其**导数**是神经网络中常用的激活函数，其表达式和求导结果如下：

### 1. **Sigmoid 函数定义**

Sigmoid 函数定义为：

$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$

### 2. **Sigmoid 的导数**

对 Sigmoid 函数求导，结果可以通过自身表示，这是其重要性质之一：

$$
\frac{d}{dx} \sigma(x) = \sigma(x) \cdot \big(1 - \sigma(x)\big)
$$

**推导过程**：

1. 设 \( \sigma(x) = \frac{1}{1 + e^{-x}} = (1 + e^{-x})^{-1} \)。
2. 使用链式法则求导：
   $$
   \frac{d}{dx} \sigma(x) = -1 \cdot (1 + e^{-x})^{-2} \cdot (-e^{-x}) = \frac{e^{-x}}{(1 + e^{-x})^2}
   $$
3. 将结果用 \( \sigma(x) \) 表示：
   - 注意到 \( \sigma(x) = \frac{1}{1 + e^{-x}} \)，因此 \( 1 - \sigma(x) = \frac{e^{-x}}{1 + e^{-x}} \)。
   - 代入导数表达式：
     $$
     \frac{d}{dx} \sigma(x) = \frac{e^{-x}}{(1 + e^{-x})^2} = \sigma(x) \cdot \frac{e^{-x}}{1 + e^{-x}} = \sigma(x) \cdot \big(1 - \sigma(x)\big)
     $$

### 3. **关键性质**

- **输出范围**：\( \sigma(x) \in (0, 1) \)，导数 \( \sigma'(x) \in (0, 0.25] \)（当 \( x=0 \) 时取得最大值 0.25）。
- **计算高效**：导数可直接用函数值计算，无需重新求导，适合反向传播。

### 4. **应用场景**

- 二分类问题的输出层激活函数（需配合交叉熵损失）。
- 历史上曾广泛用于隐藏层，现多被 **ReLU** 取代（因 Sigmoid 存在梯度消失问题）。

10. 下面开始讲 Language model

11. 首先：让计算机理解单词

    - 一开始，让单词变成编码（字典）
    - 但是这个符号并不能代表计算机能够理解单词
    - 因为这个编码没有意义
    - 因此有了 One-Hot Encoding：就是把单词变成一个向量（只有一个 1，其他都是 0）
    - 但是单词太多了、这个向量太稀疏了、因此引入了 Word Embedding
    - 因此这个 embedding 是基于：Two words are similar if they have similar word contexts

## 3.28 语言模型 Language Model

### **为什么要进行 Word Embedding？**

1. **语义表示**：将单词映射为稠密向量，使语义相似的词在向量空间中距离相近。
2. **降维**：相比 One-Hot 编码，大幅减少维度（如从数万维降至几百维）。
3. **泛化能力**：模型能捕捉词之间的关联（如“猫”和“狗”都是动物）。

### **常用方法**

1. **Word2Vec**（2013）
   - **Skip-gram**：用中心词预测上下文。
   - **CBOW**：用上下文预测中心词。
2. **Contextual Embeddings**（如 BERT、ELMo）
   - 基于上下文动态生成词向量（同一词在不同句子中向量不同）。

**经典 vs 上下文嵌入**：Word2Vec/GloVe 生成静态向量，BERT 等生成动态向量。

### **Word Embedding 的主要好处**

1. **语义相似性**

   - 将语义相近的词（如“猫”和“狗”）映射到向量空间中相近的位置，使模型能理解词之间的关系。

2. **降维高效**

   - 替代高维稀疏的 One-Hot 编码（如 10,000 维 → 300 维），减少计算和存储开销。

3. **泛化能力**

   - 能处理未见过词汇（OOV），通过词向量相似性推断语义（如“跑步”和“奔跑”）。

4. **迁移学习**

   - 预训练的词向量（如 Word2Vec）可直接用于下游任务（文本分类、机器翻译），提升小数据集的性能。

5. **上下文感知（动态嵌入）**
   - BERT 等模型生成的动态向量能区分多义词（如“苹果”在“水果”和“公司”中的不同含义）。

**总结**：从离散符号到连续向量，让机器更“懂”语言。

1. Word2Vec:如果两个词在同一个上下文中出现的概率相似，那么这两个词是相似的（通过一个上下文窗口 window 来进行判断）

2. 这个算法就是 Mikolov's CBOW 词袋模型

   - 输入：先用 one-hot 编码、然后通过一个线性变换、然后得到一个 word vector 的词向量
   - 所以这个 W 权重的特点：是一个查找表
   - 图中的例子、一个 one hot 的词向量乘以一个权重矩阵、就得到了这个单词在这个词向量空间的位置、
   - 最后通过一个 softmax 函数、得到了词汇表上的概率分布
   - 损失函数：NLL（负对数似然函数），使用梯度下降法进行优化
   - 结果：计算机能够理解单词的语义、就相当于计算机认识了单词

Mikolov 等人提出的**CBOW（Continuous Bag-of-Words）**模型是 Word2Vec 框架中的一种经典神经网络模型，用于学习单词的分布式向量表示（即词嵌入）。其核心思想是通过上下文单词预测当前目标单词，从而捕捉词汇间的语义和语法关系。

---

### **CBOW 模型原理**

1. **基本结构**：

   - **输入层**：给定一个目标单词的上下文窗口（如前后各\(c\)个单词），将上下文单词的**one-hot 向量**作为输入。
   - **隐藏层**：通过共享的权重矩阵\(W\_{V \times N}\)（\(V\)是词汇表大小，\(N\)是嵌入维度），将上下文单词的 one-hot 向量映射为低维稠密向量（词嵌入），并对这些向量**求平均**。
   - **输出层**：通过另一个权重矩阵\(W'\_{N \times V}\)将隐藏层的输出映射回高维空间，经过 Softmax 激活函数后，预测目标单词的概率分布。

2. **数学表达**：
   - 上下文单词的 one-hot 向量：\(x_1, x_2, ..., x_C\)（共\(C\)个单词）。
   - 隐藏层输出（平均上下文向量）：
     \[
     \mathbf{h} = \frac{1}{C} W^T (x_1 + x_2 + \cdots + x_C)
     \]
   - 目标单词的预测概率：
     \[
     p(w*t | w*{t-c}, ..., w\_{t+c}) = \text{Softmax}(W' \mathbf{h})
     \]
   - 损失函数：**交叉熵损失**，最小化预测与真实 one-hot 标签的差异。

---

### **CBOW 的特点**

1. **高效性**：
   - 相比 Skip-gram（另一种 Word2Vec 模型），CBOW 对**高频词**更敏感，训练速度更快（因上下文单词的均值操作减少了计算量）。
2. **适用场景**：
   - 适合小型数据集或需要快速训练的场合，但对罕见词（低频词）的捕捉较弱。
3. **与 Skip-gram 对比**：

   - **Skip-gram**：通过目标单词预测上下文，擅长处理低频词和复杂模式。
   - **CBOW**：通过上下文预测目标单词，更注重全局统计信息。

4. 接着就是要让计算机学会语言

   - 问题：如何评判计算机的语言能力
   - 即要刻画语言是大多数人说的、所以是标准的
   - 因此语言模型是概率模型，即计算一个句子的概率
   - 即如果知道概率、就能填词

5. 概率如何计算呢？

   - 把每个单词看成一组变量
   - 可以通过概率的链式法则去计算
   - P（w1, w2, w3, w4）= P(w1)P(w2|w1)P(w3|w1, w2)P(w4|w1, w2, w3)
   - 但是，这个会条件越来越长
   - 但是我们通过马尔科夫假设、就可以简化这个条件，即只需要前面的 k 个单词有关系（比如前两个单词）

6. 这个条件概率怎么算出来呢？

   - 核心就是：给了前面的单词、然后预测下一个单词
   - 朴素的想法就是计数（就是通过所有的语料库进行计算），但是弊端是没有办法应对变体，而且对相似词是不敏感的，而且本质上没有理解这句话
   - 为了克服相似词：即通过词向量的方式、把相似的词放在一起，但是也有一个问题，就是把顺序给忽略了
   - 为了顺序：就把每个向量拼接起来、然后通过一个神经网络进行训练（会考虑到顺序）但是也有问题，就是计算量太大了（而且有些句子有些是长的、有些是短的，没法固定一个大小的神经网络）而且这个模型把词的位置给限制死了，即使是一个空格，也会改变影响。同时无法刻画词之间的关系

7. 因此要设计一个神经网络，解决上面的问题

   - 保留单词间的关系，保留顺序，共享参数
   - 所以就有了 RNN（Recurrent Neural Network）
   - 先前网络的本质问题：一次只能处理一个单词
   - 因此 RNN 即要记忆前面的单词，处理的时候根据前面的记忆进行处理
   - 如何记忆？一个隐藏层本身就是一个记忆体（复用原来的隐藏层）
   - 把隐藏层加一个回路、就可以记忆了

8. RNN

   - 相当于把旧的状态作为了新的输入
   - 更新隐藏层：通过 tanh 函数
   - h*t = tanh(W_hh \* h*{t-1} + W_xh \* x_t)
   - 输出：y_t = W_hy \* h_t
   - 输入：x_t
   - 是一个典型的深度神经网络（因为在运行的时候、会随着时间递归，所以是一个很深的网络）
   - 如何训练：把所有的单词和标准值做一个比对、然后求一个 Loss 的和，然后反向传播（一样）
   - 应用：One to One、One to Many、Many to One、Many to Many

## 4.1 语言模型 Language Model

1. 拿到句子的向量（理解句子之后）、可以在输出那里再接一个分类器、就可以分类句子

2. 或者在一段句子的后面接一个分类器、就可以达到预测下一个字最大的概率、就可以生成句子。如果在这里引入交叉熵的话、那么也可以通过这个方法不断优化模型

3. RNN 的应用

   - 语言模型（Language Model）
   - 机器翻译（Machine Translation）
   - 文本生成（Text Generation）
   - 情感分析（Sentiment Analysis）

4. Backpropagation Through Time (BPTT)

   - RNN 的训练方法
   - 通过时间展开（unroll）RNN，把时间维度展开成一个深度神经网络
   - 然后通过反向传播来更新参数

### **RNN Encoder-Decoder 简介**

RNN Encoder-Decoder（编码器-解码器）是一种经典的序列到序列（**Seq2Seq**）模型架构，主要用于处理**输入和输出均为序列**的任务（如机器翻译、文本摘要、对话系统等）。其核心思想是**先编码输入序列，再解码生成输出序列**。

---

### **1. 基本结构**

#### **(1) 编码器（Encoder）**

- **作用**：将输入序列（如句子）编码为一个**固定长度的上下文向量（Context Vector）**，通常取最后一个 RNN 单元的隐藏状态。
- **结构**：通常采用 RNN（如 LSTM 或 GRU）逐步处理输入序列，每个时间步接收一个词嵌入并更新隐藏状态。

#### **(2) 解码器（Decoder）**

- **作用**：基于编码器的上下文向量，逐步生成输出序列（如翻译结果）。
- **结构**：同样是 RNN，初始状态为编码器的上下文向量。每个时间步生成一个词，并依赖前一步的输出作为当前输入（自回归生成）。

---

### **2. 关键特点**

- **序列到序列映射**：可处理变长输入和输出（如不同长度的句子）。
- **上下文向量瓶颈**：编码器需将所有输入信息压缩到单个向量中，可能导致长序列信息丢失（后续改进如**注意力机制**解决此问题）。
- **训练方式**：通过**Teacher Forcing**（使用真实标签作为解码器输入）加速收敛。

---

### **3. 典型应用**

- **机器翻译**（如英译法）：编码器读英语句子，解码器生成法语。
- **文本摘要**：编码器读长文本，解码器生成摘要。
- **对话系统**：编码器处理用户输入，解码器生成回复。

---

### **4. 改进与局限性**

#### **改进方向**：

- **注意力机制**（Attention）：让解码器动态关注编码器的不同部分，缓解长序列信息丢失问题（如 Transformer 的核心思想）。
- **双向 RNN 编码器**：更好地捕获上下文信息。

#### **局限性**：

- **长程依赖问题**：基础 RNN 难以处理超长序列（LSTM/GRU 部分缓解）。
- **训练效率低**：RNN 的串行计算难以并行化。

---

### **5. 与 Transformer 对比**

- **RNN Encoder-Decoder**：基于循环神经网络，顺序处理序列，适合短文本任务。
- **Transformer**：完全基于自注意力机制，并行计算，擅长长序列和大规模数据（如 BERT、GPT）。

---

RNN Encoder-Decoder 是早期 Seq2Seq 任务的基石，虽逐渐被 Transformer 取代，但其“编码-解码”思想仍是现代 NLP 模型的核心组成部分。（损失函数：交叉熵损失）

## 4.8 Transformer

1. Sequence-to-Sequence Learning（序列生成问题）

   - ASR（语音识别）
   - Translation
   - Dialogue（对话）
   - 首先要对输入和输出进行理解

2. 传统的 Seq2Seq 模型

---

### 1. **模型结构**

- **Encoder（编码器）**：  
  将输入序列 $X_1, X_2, \ldots, X_T$ 编码为隐藏状态序列 $h_1, h_2, \ldots, h_T$（图中蓝色部分）。
- **Decoder（解码器）**：  
  生成输出序列时，每一步的动态隐藏状态 $s_i$ 会通过**注意力层（Attention Layer）**聚焦编码器的不同隐藏状态（图中黄色部分）。
- **Attention Layer（注意力层）**：  
  计算解码器当前状态 $s_{i-1}$ 与编码器所有隐藏状态 $h_j$ 的匹配分数，生成动态上下文向量（图中绿色部分）。

---

### 2. **注意力权重公式**

图中的关键公式是**注意力权重 $\alpha_{ij}$**的计算方式（Softmax 归一化）：

$$
\alpha_{ij} = \frac{\exp\left(a(s_{i-1}, h_j)\right)}{\sum_{k=1}^{N}\exp\left(a(s_{i-1}, h_k)\right)}
$$

- **$a(\cdot)$ 是匹配函数**：  
  通过神经网络计算解码器状态 $s_{i-1}$ 和编码器状态 $h_j$ 的相关性。例如：

  $$
  a(s_{i-1}, h_j) = v_a^T \tanh(W_a s_{i-1} + U_a h_j)
  $$

  - $W_a, U_a$：可学习权重矩阵
  - $v_a$：权重向量
  - $\tanh$：激活函数

- **物理意义**：  
  $\alpha_{ij}$ 表示解码器生成第 $i$ 个输出时，对编码器第 $j$ 个输入的关注程度。

---

### 3. **动态上下文向量**

解码器每一步的上下文向量 $c_i$ 是编码器隐藏状态的加权和：

$$
c_i = \sum_{j=1}^{T} \alpha_{ij} h_j
$$

该向量会与解码器当前状态 $s_{i-1}$ 结合，生成输出（如预测下一个词）。

---

### 4. **注意力机制的作用**

- **解决长序列遗忘问题**：传统 Seq2Seq 模型需将整个输入序列压缩为固定维向量，而注意力机制允许解码器动态访问编码器的全部隐藏状态。
- **对齐（Alignment）**：在翻译等任务中，注意力权重能自动学习输入与输出位置的对应关系（如翻译时关注源语言的相关词）。

2. 编解码器模型（encoder-decoder model）

   - Encoder：通过 RNN 把输入的序列变成一个向量（上下文向量）（通常把最后时刻的状态作为编码、记为状态 c）
   - Decoder：把这个向量变成输出的序列（通过一个 RNN 来进行处理）（即是先前的语言模型、通过外加一个 MLP 多层感知机将每个结果文本输出）
   - 一开始做的是翻译问题（使用编解码器）
   - 后期如果用 CNN 作为解码器、就可以做图像生成问题（即把文本变成图像）

3. 不过如果当输入序列很长的时候

   - 就会导致信息的丢失（因为 RNN 是一个线性递增的、最后都是压成一个向量、没法把整段话去记录、没有办法对细节去做刻画）
   - 本质上的问题是最后只有一个向量（c）来进行表示、会导致信息的丢失
   - 解决方法：生成一个动态的向量（即每个单词对应一个特定的向量 ci，每个单词权重不同，这个即是注意力机制）

4. 注意力机制本质：每个单词在解码编码过程中关注不同的单词（即每个单词对其他单词的权重不同）

5. 这个权重 a 如何得到呢？

   - 通过一个神经网络的打分（score function）来进行计算（即通过一个函数来计算每个单词的权重）
   - score function：可以是一个简单的 dot product，也可以是一个复杂的函数（比如一个神经网络）
   - 然后通过 softmax 函数来进行归一化处理（转成 0-1 之间的概率），得到权重 a
   - 通过可视化 attention、可以看到这个模型确实是有效的，关注了句子中的不同单词

6. 接着人们把 attention 用在了 RNN 的编码上，即构造了 Transformer

   - RNN 的痛点：训练速度太慢了（因为天然的缺点：就是是一个串行的序列，而且当多层的时候、会有大量的 for 循环，而且解码器还需要再来一遍）
   - transformer 天然的优点：可以并行计算
   - **RNN**：通过维护隐藏状态，按顺序将当前处理的单词与之前的单词依次结合，是顺序性的依赖处理。
   - **自注意力机制**：能同时将其他相关单词的“理解”融入当前正在处理的单词，可并行处理所有单词间的关系，更高效地捕捉长距离依赖。（就是不是按顺序去读、前面的单词可以不需要读）

7. Self-Attention 可以看作是一个 query、然后对应要找的东西去找那个 key，然后把原句子中那个 value 取出来

   - 即 value vector \* score = value X score，随后求和得到 Sum 之后、即为对 query word 的新的状态

8. Self-Attention 具体实现：

   - 步骤 1 token embedding：即把所有的单词都变成一个向量（通过一个查找表）
   - 步骤 2 QKV vectors：通过一个线性变换，把每个单词的 embedding 变成 Q、K、V 三个向量（即 query、key、value）
   - 步骤 3 计算 attention score：通过 Q 和 K 的内积来计算每个单词的权重（score）(a = q \* k / sqrt(d_k))，然后通过一个线性变换来计算每个单词的权重（score）
     - 这里的 d_k 是 k 和 q 的维度（即 key 的维度），是一个缩放因子，用来防止 score 太大导致 softmax 函数的梯度消失
     - 这里的 score 是一个矩阵，表示每个单词对其他单词的权重（score）
   - 步骤 4 正则化 attention score：通过 softmax 函数来进行归一化处理（转成 0-1 之间的概率）
   - 步骤 5 计算 attention output：通过 V 和 attention score 的乘积来计算每个单词的输出 h'（即 value X score）（可以并行化进行一个 attention）
   - 每个单词，同时是 query、key、value（即每个单词都可以和其他单词进行交互）

## 4.11 Transformer && LLM

1. Self attention 的所有计算都可以表示成矩阵运算，可以使用 gpu 加速

   - 但是不是顺序处理的、为了保证保留顺序在其中的影响、需要加入一个位置编码（position encoding）
   - 位置编码：就是把每个单词的位置也加入到这个向量中（即把每个单词的位置信息 one-hot 也加入到这个向量中）
   - 可以完全取代 RNN、所以在 encoder 和 decoder 中使用了 self-attention layers 即喂 self attention model

2. transformer 的一个 encoder 有一个 attention 模块、decoder 有两个 attention 模块

   - encoder 中的第二个 attention 模块是一个交叉的注意力机制（cross attention），即 decoder 中的每个单词都可以和 encoder 中的每个单词进行交互

### **Transformer 简介**

Transformer 是由 **Google** 在 2017 年提出的神经网络架构（论文 _"Attention Is All You Need"_），彻底改变了自然语言处理（NLP）领域。它完全基于**自注意力机制（Self-Attention）**，摒弃了传统的循环（RNN）和卷积（CNN）结构，实现了**并行计算**和**长距离依赖建模**，成为现代大语言模型（如 BERT、GPT）的基础。

---

## **1. 核心思想**

- **自注意力（Self-Attention）**：每个词可以动态关注输入序列的所有词，计算其相关性权重，从而捕获全局依赖关系。
- **并行计算**：不同于 RNN 的串行计算，Transformer 可同时处理所有输入位置，大幅提升训练速度。
- **编码器-解码器架构**：适用于序列到序列（Seq2Seq）任务（如翻译），但也可单独使用（如 BERT 仅用编码器，GPT 仅用解码器）。

---

## **2. 主要结构**

### **(1) 编码器（Encoder）**

- 由 **N 个相同层**（通常 N=6）堆叠而成，每层包含：
  - **多头自注意力（Multi-Head Attention）**：并行计算多组注意力，增强模型表达能力。
  - **前馈神经网络（Feed Forward Network, FFN）**：逐位置非线性变换。
  - **残差连接（Residual Connection） + 层归一化（LayerNorm）**：缓解梯度消失，稳定训练。

### **(2) 解码器（Decoder）**

- 同样由 N 个相同层堆叠，但额外引入：
  - **掩码自注意力（Masked Self-Attention）**：防止解码时“偷看”未来信息（确保自回归生成）。
  - **编码器-解码器注意力（Cross-Attention）**：解码器关注编码器的输出，实现跨序列交互。

### **(3) 输入输出处理**

- **位置编码（Positional Encoding）**：通过正弦/余弦函数注入位置信息，弥补自注意力对顺序不敏感的缺陷。
- **嵌入层（Embedding）**：将词映射为高维向量。

---

## **3. 关键优势**

- **长距离依赖建模**：自注意力直接计算任意两个词的关系，克服了 RNN 的梯度消失问题。
- **高效并行训练**：适合 GPU 加速，比 RNN 训练快数倍。
- **可扩展性强**：通过堆叠更多层和增大隐藏维度，可构建超大规模模型（如 GPT-3）。

---

## **4. 典型应用**

- **机器翻译**（原始论文任务）：编码器读源语言，解码器生成目标语言。
- **文本生成**（如 GPT）：仅用解码器进行自回归生成。
- **文本理解**（如 BERT）：仅用编码器进行双向上下文编码。
- **多模态任务**（如 Vision Transformer）：适配图像、语音等非文本数据。

---

## **5. 局限性**

- **计算复杂度高**：自注意力的计算量随序列长度平方增长（如长文本处理成本高）。
- **数据需求大**：依赖海量训练数据，小数据场景易过拟合。
- **解释性差**：注意力权重难以直观理解模型的决策过程。

---

3. decoder 中的需要一个 mask

   - 因为需要做矩阵计算、然后矩阵的大小是要有限制的
   - 通过 mask 可以让模型只关心部分的单词
   - **自注意力掩码**：用于编码器和解码器，目的是忽略填充标记（padding tokens），填充标记对应位置为 -inf 。
   - **交叉注意力掩码**：仅用于解码器，用于忽略源序列中的填充标记，本质上和前一种相同
   - **因果掩码**：仅用于解码器，只关注已生成的词，当前词之后的词对应位置为 -inf ，当前词及之前已生成词对应位置为 0 。

4. 损失函数：交叉熵，优化：梯度下降

5. Pre-trained Language Models（预训练语言模型）

   - 首先通过无监督方法、对大规模的语料进行预训练（即通过无监督的方法进行训练）
   - 然后通过有监督的方法进行微调（即通过有监督的方法进行训练）

6. BERT

   ### 输入

   • **词元**：原始文本经分词（如 WordPiece）得到的单词或子词。
   • **特殊标记**：开头 `[CLS]`（用于分类等任务）、结尾 `[SEP]`（分隔句子）。
   • **位置编码**：表示词元在序列中的位置。
   • **词嵌入**：词元映射到固定维度的向量，与位置编码相加得到最终输入。

   ### 输出

   • **最后一层隐藏状态**：每个输入词元在最后一层 Transformer 编码器的输出向量，用于多种任务。
   • **[CLS]标记输出**：`[CLS]` 标记对应向量，常用于分类任务 。

7. BERT 具体步骤

   - 把 BERT 作为 encoder，CLS token（Classification Token）是 BERT 在输入序列起始位置添加的一个特殊标记，主要用于分类任务
   - Task1：通过 Masked Language Model（MLM）来进行预训练（即把句子中的一些单词随机的 mask 掉，然后让模型去预测这个单词是什么）（完形填空）
   - Task2：通过 Next Sentence Prediction（NSP）来进行预训练（即判断两个句子是否是连续的）
   - 微调，通过有监督的方法进行微调（即通过有标签的数据进行训练）比如情感分析、命名实体识别、信息抽取、句子因果关系预测等任务。这里是微调分类器
   - 损失函数是语言模型的负对数似然损失（Negative Log-Likelihood Loss）​

8. 把解码器也变成预训练的了、那么就是 GPT 了（Generative Pre-trained Transformer）

## 4.15 LLM

1. 一种使用方式是进行微调、还有一种方式是提示词工程加上 RAG 检索增强（Retrieval-Augmented Generation）

2. 微调：

   - 目前在非常大的模型下已经不太现实了（因为参数太多了、而且数据量也很大）
   - 但是在小模型下、还是可以进行微调的（比如 1 亿参数的模型）
   - 微调的本质：在本地通过新的数据进行重新训练（即通过新的数据进行训练）

3. PEFT（Parameter-Efficient Fine-Tuning）

   - 通过参数高效微调的方法、来进行微调（即只训练一部分参数）（但是能达成近似的效果）
   - 就是只训练一小部分参数、而不是全部的参数
   - LoRA：Low-Rank Adaptation，低秩适配（即把原来的权重矩阵分解成两个低秩矩阵的乘积）
   - 通过低秩矩阵的乘积来进行微调（即只训练一部分参数）（就是矩阵很大、但是有用的参数就一小部分）
   - “Tunable Soft Prompt”就是在提示微调方法中，那些能够被优化调整的、具有连续可优化特性的提示向量 。它们能够在不改变预训练模型主体参数的情况下，通过对这些软提示的调整来影响模型的输出行为。

4. LLM 的涌现能力

   - Emergent abilities：当模型的参数达到一定规模时，模型会展现出一些意想不到的能力（比如推理、数学、逻辑等）
   - 这个能力是随着参数的增加而增加的
   - 但是这个能力是不可预知的（即不是通过训练出来的）

5. 提示工程（Prompt Engineering）

   - 通过提示词来引导模型的输出
   - 提示词：就是给模型一个提示，让模型知道要做什么

6. Few-Shot Prompting

   - 通过给模型一些例子来引导模型的输出
   - 这个例子可以是自然语言、也可以是代码、也可以是其他的形式
   - 现学现用，但是没有参数更新

7. Chain-of-Thought Prompting

   - 思维链提示：一问一答的方式来引导模型的输出
   - 输出思考过程
   - 问题：没有与外界交互

8. ReAct

   - 解决了与外界交互的逻辑
   - ReAct​ 是一种结合 ​ 推理（Reasoning）​​ 和 ​ 行动（Action）​​ 的框架，主要用于增强大语言模型（LLM）在复杂任务中的表现，使其能够更灵活地解决需要多步推理和外部工具调用的任务。

9. RAG（Retrieval-Augmented Generation）

   - 检索增强生成：通过检索来增强模型的生成能力
   - 四个部分：
     - Embedding
     - Vector DB
     - 检索器
     - LLM
   - 首先进行 embedding，然后进行 retrieval（通过计算相似度的模式）

## 4.22 CNN

1. 彩色图片可以看作是一个三维的矩阵（长、宽、RGB），而黑白图片可以看作是一个二维的矩阵（长、宽）

2. 使用传统的 NN 的问题：会导致参数过多（因为每个像素都要连接到每个神经元）

3. 1-D Convolution

   - 1-D 卷积：就是对一维的序列进行卷积操作（比如时间序列、文本序列等）
   - 卷积核的大小可以根据需要进行调整（比如 3x1、5x1 等）
   - 卷积操作的好处：可以提取出局部特征，而且参数少了很多（因为只需要训练卷积核的参数）

4. CNN 通过卷积核（filter）来进行特征提取

   - 卷积核：就是一个小的矩阵（比如 3x3），通过这个卷积核和原始图片进行卷积操作，得到一个新的矩阵（feature map）
   - 卷积操作：就是把卷积核在原始图片上滑动，然后计算卷积核和原始图片的点积，得到一个新的矩阵（feature map）
   - 卷积操作的好处：可以提取出局部特征，而且参数少了很多（因为只需要训练卷积核的参数）

5. Multiple Input Channels（“3-D” Convolution）

   - 多通道输入：就是对多通道的图片进行卷积操作（比如 RGB 图片）
   - 卷积核的大小可以根据需要进行调整（比如 3x3x3、5x5x3 等）

6. Feature Map

   - Amapthatstores the locations of a specific feature activated by a filter
   - 特征图：就是卷积操作的结果（feature map）
   - 特征图的大小可以根据需要进行调整（比如 3x3、5x5 等）

7. Multiple Filters

   - 多个卷积核：就是对多通道的图片进行卷积操作（比如 RGB 图片）
   - 每个卷积核提取出不同的特征（比如边缘、纹理等）

8. Multiple Feature Maps

   - For example, if we had 6 5x5 filters, we’ll get 6 separate activation maps:
   - 多个特征图：就是对多通道的图片进行卷积操作（比如 RGB 图片）

9. Padding

   - 填充：就是在原始图片的边缘添加一些像素（比如 0 或者其他的值）
   - 填充的好处：可以保持卷积操作的结果和原始图片的大小一致（即不改变原始图片的大小）
   - 不至于把边缘的信息给忽略

10. Pooling (池化)

    - 池化：就是对特征图进行下采样操作（比如 max pooling、average pooling 等）
    - 池化的好处：可以减少特征图的大小，而且可以提取出更高层次的特征（比如边缘、纹理等）
    - 池化操作的好处：可以减少特征图的大小，而且可以提取出更高层次的特征（比如边缘、纹理等）
    - Max pooling：就是取特征图中最大的值（比如 2x2 的特征图，取最大的值）
    - Max pooling selects the brighter pixels from the image.（变得更亮）
    - Mean pooling：就是取特征图中平均值（比如 2x2 的特征图，取平均值）
    - Mean pooling method smooths out the image and hence the sharp features may not be identified.（变得模糊）

## 4.25 CNN & CV

1. 卷积核大小、图片大小和输出大小的关系

   - Input size: N×N
   - Filter size: F×F
   - Output size: (N - F) / stride + 1
   - 实际的时候把边缘 padding 了一层 0
   - Output size: (N +2P- F) / stride + 1

2. ​stride（步长）​ 是指卷积核在输入图像上滑动时的移动步幅。具体来说：​ 定义 ​：Stride 表示卷积核每次在水平或垂直方向上移动的像素数量。例如：当 stride=1 时，卷积核每次移动 1 个像素；当 stride=2 时，卷积核每次跳过 1 个像素，移动 2 个像素。

3. Can we let a CNN act as an MLP? How?

   - 仅保留 CNN 的全连接部分
   - 使用 1×1 卷积模拟全连接

4. Can we apply CNN for texts?

   - 把文本的矩阵当作图片，可以用的

5. Why use residual connection?（残差网络 ResNet ）

   - ResNet 是一种深度卷积神经网络架构，旨在解决深层网络训练中的梯度消失和退化问题。其核心思想是通过引入残差连接（Residual Connections）来实现更深层次的网络训练。

   1. gradients can propagate fasterthroughahighway(recallLSTM) （对于优化很有好处）
   2. within each block, only small residuals have to be learned
   3. letdeepermodeltoperformasgoodasshallowermodelbycopying the learned layers from the shallower model and setting dditional layers to identity mapping.（让深层的网络复习到浅层的特征）

6. 下面是 CV 的部分、讲了机器视觉的任务

7. 图像分割

   - 将图片分成不同的区域
   - 但是不需要对这个原图进行分割、可以先在 downsampling 的结果上进行分割然后再复原成原来的大小（unpooling，upsampling）
   - 对图像分割的时候实际不需要和原来的大小一样（所以可以 Upsampling）
   - 如果 Fully Convolutional 的话、那么开销太大了

## 4.29 CV

0. 在 UNet 中，转置卷积矩阵（Transposed Convolution Matrix）主要用于**上采样（Upsampling）**操作，尤其是在解码器（Decoder）部分。以下是具体应用方式及其作用：

---

### 1. **UNet 的架构背景**

UNet 是一种对称的编码器-解码器结构，其中：

- **编码器**通过卷积和池化逐步下采样，压缩空间维度并提取高层特征。
- **解码器**通过上采样和转置卷积逐步恢复空间分辨率，同时结合编码器的跳跃连接（Skip Connections）保留细节信息。

转置卷积矩阵在解码器中用于替代传统的插值上采样（如双线性插值），实现**可学习的上采样**。

---

### 2. **转置卷积矩阵的作用**

在 UNet 中，转置卷积矩阵（即图中的 $C^{\mathrm{T}}$）通过以下步骤实现上采样：

- **输入**：低分辨率特征图（例如 4×4）展平为列向量（16×1）。
- **矩阵乘法**：与转置卷积矩阵 $C^{\mathrm{T}}$（例如 16×4）相乘，生成高分辨率输出向量（16×1）。
- **重塑（Reshape）**：将输出向量重新排列为高分辨率特征图（例如 8×8）。

**关键点**：

- **参数可学习**：转置卷积矩阵的权重在训练中通过反向传播优化，自动学习最适合数据的上采样方式。
- **局部连接性**：如图中所述，输入的一个值通过矩阵乘法影响输出中的多个位置（如“1 值 →9 值”），形成重叠的重建区域。

---

### 3. **UNet 中的实际应用**

- **跳跃连接融合**：解码器的转置卷积输出会与编码器对应层的特征图拼接（Concatenate），补充空间细节。
- **逐层恢复分辨率**：例如，从底层特征图的 4×4 上采样到 8×8，再到 16×16，最终恢复到原始输入尺寸。

---

### 4. **优势与注意事项**

- **优势**：
  - 比插值方法更灵活，能适应复杂的数据分布。
  - 通过训练自动优化上采样核（即转置卷积矩阵）。
- **潜在问题**：
  - 可能产生棋盘效应（Checkerboard Artifacts），可通过调整核大小或使用重叠平滑缓解。

### 1. **从普通卷积矩阵出发**

- 常规卷积操作可以通过**将卷积核重排为稀疏矩阵**（图中记为 $C$，尺寸 4×16）来实现矩阵乘法形式的卷积。
  - 例如：4×4 输入 + 3×3 卷积核 → 2×2 输出，对应的卷积矩阵 $C$ 的每一行是卷积核的展开形式，按滑动窗口位置排列。

### 2. **转置卷积矩阵的生成**

- 直接对卷积矩阵 $C$ 进行**转置**，得到转置卷积矩阵 $C^{\mathrm{T}}$（尺寸 16×4）。
  - **数学关系**：若 $C$ 是下采样的卷积矩阵，则 $C^{\mathrm{T}}$ 是其对应的上采样矩阵。
  - **作用**：通过矩阵乘法 $C^{\mathrm{T}} \cdot \text{（输入列向量）}$，将低维输入（如 4×1）映射到高维输出（如 16×1）。

### 3. **关键特性**

- **局部连接性**：如图中标注，$C^{\mathrm{T}}$ 的每个输入值会影响到输出中的多个位置（如“1 值 →9 值”），形成重叠的上采样区域。
- **可学习的上采样**：实际应用中（如 UNet），$C^{\mathrm{T}}$ 的权重通过训练优化，而非固定数学转置。

1. 为了在复原图片为原来的大小的时候、不仅仅采用原始的马赛克的放大方式（重复、取 0）

   - 把卷积核铺开来，得到 Convolution Matrix（卷积矩阵）
   - 转置之后得到 Transposed Convolution Matrix（转置卷积矩阵）
   - 通过 Transposed Convolution 做 Upsampling（逆卷积的思想，但是并不是在复原图片，依然有参数需要学习）
   - 类似于 encoder 和 decoder 的关系（在这里是 convolution 和 deconvolution 的翻译关系）
   - 这个图片版的模型就叫做 U-Net（因为长得像 U）

2. 然后讲了目标监测任务

   - 首先是 Single Object 的场景
   - 分类+定位的综合操作（Single Object = Class Scores + Box Coordinates）
   - 但是问题是不能预测有多少个目标、也不能预测目标的种类

3. 解决方法：Region Proposals: Selective Search

   - 通过一个算法来进行选择（即通过一个算法来进行选择）
   - 这个算法的思路是：先把图片分成很多个小块，这些小块里面可能有目标
   - R-CNN：首先通过 Selective Search 算法来进行选择，然后通过 CNN 来进行分类和定位（即通过 CNN 来进行分类和定位），但是原始的方法太慢了
   - Fast R-CNN：先卷积、拿到 feature map、然后再做 R-CNN
   - Faster R-CNN：做一个 local 的 Region Proposal 方法、及分割出可能有目标的区域

4. 进一步改进：Yolo

   - 把目标监测和区域监测合并到一步里

5. 其他任务：Image Captioning（图像描述）

   - 即是一个翻译问题
   - 使用 Encoder-Decoder with Attention 方法解决
   - 把 feature map 接到 Transformers
   - 进一步优化：不需要 CNN 的卷积、因为 Transformer 和卷积都是提取特征的
   - 所以有了 Vision Transformer（ViT）
   - ViT：把图片变成一个个区块，然后通过 Transformer 来进行处理（即把图片变成一个个区块，然后通过 Transformer 来进行处理）
   - BEIT：BERT Pre-Training of Image Transformers

## 5.6 CV & kmeans & Dimensionality Reduction

1. CLIP – Contrastive Language-Image Pretraining

   - CLIP 是一种结合了图像和文本的预训练模型，旨在通过对比学习来理解图像和文本之间的关系。它使用了大规模的图像-文本对进行训练，使得模型能够在没有明确标签的情况下进行图像和文本的匹配和检索。CLIP 的核心思想是通过对比学习来最大化图像和文本之间的相似性，从而实现跨模态的理解和生成。
   - 通过计算向量之间的相似度来实现

| **对比维度**   | **有监督学习 (Supervised Learning)**                         | **无监督学习 (Unsupervised Learning)**         | **强化学习 (Reinforcement Learning)**              |
| -------------- | ------------------------------------------------------------ | ---------------------------------------------- | -------------------------------------------------- |
| **定义**       | 通过**标注数据**（输入-输出对）学习映射关系。                | 从**无标注数据**中发现隐藏模式或结构。         | 通过**试错**和**环境反馈**学习最优策略。           |
| **数据要求**   | 需要大量标注数据（X 和 Y）。                                 | 仅需输入数据（X），无标注。                    | 无需标注数据，但需定义**环境、状态、动作、奖励**。 |
| **典型算法**   | - 回归：线性回归、决策树<br>- 分类：SVM、逻辑回归、CNN       | - 聚类：K-Means、DBSCAN<br>- 降维：PCA、t-SNE  | - Q-Learning<br>- DQN<br>- 策略梯度（PPO）         |
| **目标**       | 最小化预测误差（如交叉熵、MSE）。                            | 发现数据内在结构（如聚类、降维）。             | 最大化累积奖励（长期回报）。                       |
| **应用场景**   | - 图像分类<br>- 语音识别<br>- 房价预测                       | - 客户分群<br>- 异常检测<br>- 推荐系统（部分） | - 游戏 AI（AlphaGo）<br>- 自动驾驶<br>- 机器人控制 |
| **优点**       | - 预测精度高（若有足够标注数据）<br>- 可解释性强（如决策树） | - 无需标注数据<br>- 可探索未知模式             | - 适应动态环境<br>- 能学习长期策略                 |
| **缺点**       | - 依赖标注数据（成本高）<br>- 过拟合风险                     | - 结果难以评估（无标准答案）<br>- 可解释性差   | - 训练不稳定<br>- 需要大量试错（样本效率低）       |
| **反馈类型**   | 显式反馈（标注数据）。                                       | 无反馈（仅数据本身）。                         | 延迟反馈（环境给出的奖励/惩罚）。                  |
| **是否需交互** | 否（离线学习）。                                             | 否（离线学习）。                               | 是（需与环境交互）。                               |

2. 还有一种任务：聚类任务

   - 场景：需要处理无标签的数据、即进行无监督的学习
   - 聚类：把数据按照相似度进行分组
   - 方法：给每个组选择一个代表（centroid），每个数据有一个标签来指向这个代表

3. K-means 聚类算法步骤：

   - 选择 k 个随机数据点作为初始质心（聚类中心）
   - 将每个数据点分配给最近的质心（使用 L2 距离公式计算）（label update）
   - 根据当前聚类成员重新计算质心（取均值）（centroid update）
   - 重复分配和更新步骤直至收敛

   1. 关键公式：

      - 距离计算：$L_2(x,\mu^k)=\sqrt{\sum_{m=1}^{d}(x_i-\mu_m^k)^2}$
      - 质心更新：$\mu^k=\frac{1}{C_k}\sum_{x\in C_k}x$

   2. 终止条件：
      - 达到预设的收敛标准（如质心不再显著变化）

4. 收敛准则：

   - 无（或最小）数据点到不同簇的重新分配
   - 无（或最小）质心的变化
   - 误差平方和（SSE）的最小减少量

5. 误差平方和（SSE）公式：

   - $\min_{\{\mu^k\}_{k = 1}^K}\sum_{k = 1}^K\sum_{x\in C_k}L(x - \mu^k)$
   - 其中质心计算：$\mu^k=\frac{1}{C_k}\sum_{x\in C_k}x$

6. K-means 时间复杂度分析：

   - 计算两个实例间距离的时间复杂度：O(d)，d 为向量维度
   - 重新分配聚类簇的时间复杂度：O(knd)，k 为簇数，n 为实例数
   - 计算质心的时间复杂度：O(nd)，每个实例向量被加到某个质心一次
   - 总时间复杂度：O(Iknd)，I 为迭代次数

7. 不好的地方：

   - 结果是不确定的
   - 首先、聚类的个数是不确定的
   - 其次、初始的质心是随机的
   - 即有 Sensitivity to Initial Centroids (Seeds)

8. 如何选择 K 值

   - 使用肘部法确定最佳 K 值
   - 计算每个 K 值对应的组内平方和（WSS）
   - WSS 定义为簇成员与其质心间距离平方和
   - 选择 WSS 下降趋势变缓的 K 值（肘部点）

9. 另一种方法：k-means++ 如何选择初始质心

   - 优化初始质心选择
   - 步骤：随机选择第一个中心点
   - 计算每个点与最近已选中心的距离 D(x)
   - 按 D(x)^2 的概率分布选择新中心点
   - 重复选择直到选出 k 个中心点
   - 最后运行标准 k-means 算法

10. 应用：

    - 图像分割
    - 文本聚类
    - 图像压缩 replace each pixel value with its nearby centroid

11. Pros and Cons

    - Pros：简单易用、快速收敛、适用于大规模数据
    - Cons：对初始质心敏感、对噪声和异常值敏感、需要预先指定 K 值，把聚类看作是一个球形，数据是没有均值的（只有向量）

12. 然后再讲了 Dimensionality Reduction

    - 降维：把高维的数据降到低维（即把高维的数据降到低维）
    - 目的：减少数据的维度、去除冗余信息、保留重要核心的信息（使得能够做概率处理、降低复杂度等）

## 5.9 Dimensionality Reduction & Deep Generative Models

1. 降维有两类方法

   - 线性降维：PCA、LDA...
   - 非线性降维：t-SNE、UMAP...

2. PCA（主成分分析）

   - PCA 是一种线性降维方法，旨在通过正交变换将数据投影到较低维度的空间中，同时保留数据的主要特征。它通过计算数据的协方差矩阵并找到其特征值和特征向量来实现降维。PCA 的核心思想是选择具有最大方差的方向作为新的坐标轴，从而减少数据的维度。
   - 相当于保留了数据在某一个方向上变化最剧烈、这个就是一个主要的成分。因此有最大方差的方向就是主成分
   - 相当于一个 QP 问题（Quadratic Programming Problem），即一个二次规划问题（要最大化协方差）
   - 解法：对数据进行中心化处理（去均值），然后计算协方差矩阵，接着计算协方差矩阵的特征值和特征向量，最后选择前 k 个特征向量（特征值）作为新的基底进行组合
   - 如何决定 k 值：通过累计贡献率来决定（即前 k 个特征值的和占总特征值的比例）（info loss）
   - 应用：图像压缩、数据可视化、数据预处理、人脸识别
   - PCA =a neural network with one hidden layer (linear activation)

3. Auto-encoder

   - 自编码器：是一种无监督学习的神经网络模型，旨在通过编码器将输入数据压缩到低维空间中，然后通过解码器将其重建为原始数据。自编码器的核心思想是通过最小化输入数据和重建数据之间的差异来学习有效的低维表示。
   - 由编码器和解码器两部分组成
   - 编码器：将输入数据映射到低维空间（latent space）
   - 解码器：将低维表示映射回原始数据空间
   - 训练目标：最小化输入数据和重建数据之间的差异（通常使用均方误差作为损失函数）
   - 应用：图像去噪、异常检测、特征提取、图像搜索
   - Deep Auto-encoder：深度自编码器是自编码器的扩展版本，具有多个隐藏层。它通过堆叠多个编码器和解码器来学习更复杂的低维表示。深度自编码器可以捕捉到更高层次的特征，并在处理复杂数据时表现更好。
   - Denoising Auto-encoder：去噪自编码器是一种特殊类型的自编码器，旨在从部分损坏或噪声数据中恢复原始数据。它通过在输入数据中添加噪声来训练模型，使其能够学习到更鲁棒的特征表示。去噪自编码器的训练目标是最小化输入数据和重建数据之间的差异，同时忽略噪声部分。（应用： remove noise from data.）

4. Probability Distributions for Images：学习的是图片的概率分布

   - Goal: find a p𝑚𝑜𝑑𝑒𝑙(x) that approximates p𝑑𝑎𝑡𝑎(x) well.
   - Generator G：一个神经网络，将随机噪声 z 映射到数据空间 x（一个概率转换器）
   - Discriminator D：一个神经网络，判断输入数据 x 是真实数据还是生成数据（要让两个分布尽可能接近）

5. Generative Adversarial Network (GAN)

   - GAN 是一种生成对抗网络，由生成器和判别器组成。生成器负责生成新的数据样本，而判别器负责判断输入样本是真实的还是生成的。（两个目标其实是是相反的）GAN 的核心思想是通过对抗训练来优化生成器和判别器，使得生成器能够生成更真实的数据样本。
   - 通过对抗训练来优化生成器和判别器
   - 目标函数：最小化生成器的损失函数和最大化判别器的损失函数
   - 损失函数：交叉熵损失函数
   - 应用：图像生成、图像修复、图像超分辨率

## 5.13 Deep Generative Models

1. Deep Convolutional GANs (DCGAN)

   - DCGAN 是一种深度卷积生成对抗网络，结合了卷积神经网络（CNN）和 GAN 的优点。它使用卷积层来提高生成器和判别器的性能，从而生成更高质量的图像。DCGAN 的核心思想是通过使用卷积层来捕捉图像的空间特征，从而提高生成器和判别器的性能。
   - 通过使用卷积层来捕捉图像的空间特征
   - 通过使用反卷积层来进行上采样
   - 应用：图像生成、图像修复、图像超分辨率
   - 比如把男的戴眼镜-男的不带眼睛+女的不带眼镜=女的戴眼镜（向量运算）

2. Conditional GANs

   - 条件 GAN 是一种条件生成对抗网络，通过在生成器和判别器中引入条件信息来控制生成的样本。它可以根据给定的条件（如标签、文本描述等）生成特定类型的数据。条件 GAN 的核心思想是通过引入条件信息来控制生成的样本，从而实现更精确的生成。
   - 通过在生成器和判别器中引入条件信息来控制生成的样本
   - 应用：固定框架的风格替换（day to night， BW to color， sketch to photo 等）

3. CycleGAN: Domain Transformation （风格迁移）

   - CycleGAN 是一种循环一致性生成对抗网络，旨在实现无监督的图像到图像转换。它通过引入循环一致性损失来确保生成的图像在两个域之间保持一致。CycleGAN 的核心思想是通过引入循环一致性损失来实现无监督的图像到图像转换，从而避免了对成对训练数据的需求。
   - 通过引入循环一致性损失来实现无监督的图像到图像转换
   - 具体实现：两个转换器 GAB 和 GBA，分别将图像从域 A 转换到域 B 和从域 B 转换到域 A。通过引入循环一致性损失来确保生成的图像在两个域之间保持一致。通过判断 A 的 Loss 来判断是否能够复原
   - 无监督
   - 应用：风格迁移、图像修复、图像超分辨率

4. Variational Autoencoders (VAE)

   - VAE 是一种变分自编码器，通过引入变分推断来学习数据的潜在表示。它将输入数据映射到潜在空间，并通过重参数化技巧来实现高效的采样。VAE 的核心思想是通过引入变分推断来学习数据的潜在表示，从而实现更高效的生成。（通过 encoder 和 decoder 来进行生成）
   - 通过引入变分推断来学习数据的潜在表示
   - 可以控制生成图片的风格
   - 应用：表情生成、图像修复、图像超分辨率

## 5.20 Deep Generative Models && Reinforcement Learning

1. 以前的模型的缺陷

   - 自编码器 VAE：降维模型、损失细节、生成的效果不好

2. 扩散模型：逐步生成图片

   - 把图片变成噪声，将生成图片的过程认为是不断的去噪声的过程
   - 有两个过程：正向扩散和反向扩散
   - 正向扩散：将图片变成噪声的过程
   - 反向扩散：将噪声变成图片的过程
   - 正向每一步：将图片加上一个噪声 gaussian noise
   - 反向每一步：将噪声减去一个噪声（让神经网络去预测哪里是噪声）

3. 有监督学习和无监督学习的区别

   - 有监督学习：通过标签来进行训练（即通过标签来进行训练）（例子：分类、回归等）
   - 无监督学习：通过数据本身来进行训练（即通过数据本身来进行训练）（例子：聚类、降维等）
   - 强化学习：通过奖励来进行训练（即通过奖励来进行训练）（例子：游戏、控制等）

4. 马尔可夫决策过程（MDP）

   - MDP 是一种数学模型，用于描述强化学习中的决策过程。它由状态空间、动作空间、转移概率和奖励函数组成。MDP 的核心思想是通过最大化累积奖励来优化决策策略，从而实现最优的决策。
   - 状态空间：所有可能的状态集合
   - 动作空间：所有可能的动作集合
   - 转移概率：从一个状态到另一个状态的概率
   - 奖励函数：每个状态下采取某个动作所获得的奖励
   - 目标：最大化累积奖励

5. Q-learning

   - Q-learning 是一种无模型的强化学习算法，通过学习状态-动作值函数来优化决策策略。它通过与环境的交互来更新 Q 值，从而实现最优的决策。Q-learning 的核心思想是通过学习状态-动作值函数来优化决策策略，从而实现最优的决策。
   - Q 值：表示在某个状态下采取某个动作所获得的预期奖励
   - 更新公式：$Q(s,a) = Q(s,a) + \alpha[r + \gamma \max_{a'}Q(s',a') - Q(s,a)]$
   - 目标：最大化累积奖励
   - Problem with Q-learning:Too Many States!

## 5.23 Reinforcement Learning

1. 强化学习的目标是最大化累积奖励

   - 通过与环境的交互来更新 Q 值，从而实现最优的决策
   - 通过学习状态-动作值函数来优化决策策略，从而实现最优的决策
   - 通过最大化累积奖励来优化决策策略，从而实现最优的决策

2. 蒙特卡洛+强化学习

   - 蒙特卡洛方法：通过随机采样来估计期望值
   - 蒙特卡洛强化学习：通过随机采样来估计 Q 值
   - 蒙特卡洛强化学习的核心思想是通过随机采样来估计 Q 值，从而实现最优的决策
   - 通过与环境的交互来更新 Q 值，从而实现最优的决策
   - 通过最大化累积奖励来优化决策策略，从而实现最优的决策
   - 缺陷：需要完整的轨迹才能进行更新（即需要完整的轨迹才能进行更新），无穷尽

3. 时间差分学习（Temporal Difference Learning）

   - TD 学习：结合了蒙特卡洛方法和动态规划的方法
   - TD 学习的核心思想是通过与环境的交互来更新 Q 值，从而实现最优的决策
   - 通过最大化累积奖励来优化决策策略，从而实现最优的决策
   - TD 学习的核心思想是通过与环境的交互来更新 Q 值，从而实现最优的决策
   - 通过最大化累积奖励来优化决策策略，从而实现最优的决策
   - 递归公式：$Q(s,a) = Q(s,a) + \alpha[r + \gamma Q(s',a') - Q(s,a)]$

4. Q-learning 的流程

   - 初始化 Q 值
   - 选择动作（ε-greedy 策略）
   - 执行动作，观察奖励和下一个状态
   - 更新 Q 值
   - 重复以上步骤，直到收敛

5. Q-learning 的优缺点

   - 优点：简单易用、收敛速度快、适用于大规模数据
   - 缺点：对初始 Q 值敏感、对噪声和异常值敏感、需要预先指定学习率和折扣因子
   - 需要大量的训练数据才能收敛
   - 需要大量的计算资源才能收敛

6. DQN（Deep Q-Network）

   - DQN 是一种深度强化学习算法，通过引入深度神经网络来近似 Q 值函数。它结合了 Q-learning 和深度学习的优点，从而实现更高效的决策。DQN 的核心思想是通过引入深度神经网络来近似 Q 值函数，从而实现更高效的决策。
   - 通过引入深度神经网络来近似 Q 值函数
   - 通过经验回放和目标网络来提高训练效率
   - 应用：游戏、机器人控制、自动驾驶等
   - 把状态看作图片、输入到 DNN 里
   - 训练：预测 Q 值、计算 MSE 损失、更新参数
   - 目标：最大化累积奖励
   - 把迁移的历史存储下来、放到数据集中
   - 问题：这个 target 也在不断的更新、所以需要一个 target network 来进行更新

7. DQN+Experience Replay 的流程

   - 初始化经验回放池
   - 初始化 Q 网络和目标网络
   - 选择动作（ε-greedy 策略）
   - 执行动作，观察奖励和下一个状态
   - 将经验存储到经验回放池中
   - 从经验回放池中随机采样一批数据
   - 更新 Q 值
   - 重复以上步骤，直到收敛

8. Policy Learning

   - 策略学习：直接学习策略函数 π(a|s)，即在给定状态下选择动作的概率分布
   - 策略函数：表示在给定状态下选择动作的概率分布
   - 策略梯度方法：通过计算策略函数的梯度来优化策略
   - 策略迭代：通过交替执行策略评估和策略改进来优化策略
   - 策略评估：计算当前策略的价值函数
   - 策略改进：通过最大化价值函数来优化策略
   - Episode：一个完整的轨迹，从初始状态到终止状态
   - 轨迹：一个完整的状态-动作序列
   - 轨迹的价值：轨迹中所有奖励的总和
   - 轨迹的价值函数：表示在给定状态下采取某个动作所获得的预期奖励
   - 目标：最大化轨迹的价值函数

9. Policy Gradient 流程

   - 初始化策略函数
   - 选择动作（根据当前策略函数）
   - 执行动作，观察奖励和下一个状态
   - 更新策略函数
   - 重复以上步骤，直到收敛

## 5.27 Reinforcement Learning

1. R(θ) = E[∑t=0T-1γtrt]

   - 这个公式表示在给定策略 θ 下，轨迹的价值函数
   - 其中 γ 是折扣因子，rt 是在时间 t 时刻获得的奖励
   - 相当于求一个函数的最大值
   - 这里老师课上讲了这个函数求导的过程
   - 用样本真值去近似这个函数的期望值（条件概率展开、链式规则）

2. 也可以把这里的 logP 看作是 RNN 中的解码器

   - 因此这里的策略梯度和连续的分类器很像
   - 这里就变成了寻找最有可能的轨迹的过程了

3. 然后讲了一个 alpha go 的案例学习

   - 用神经网络评估状态
   - 由于落子自由度比较大、因此游戏空间非常大
   - 共有 4 个内容需要进行设置：state、action、reward、policy
   - state：通过 CNN 来进行提取、可以被视作是一个图片
   - action：落子的位置
   - reward：胜负结果、赢了就 +1、输了就 0 分
   - policy：通过一个神经网络来进行预测、即通过一个神经网络来进行预测执行 action 的概率
   - 一共有 2 个网络：policy network 和 value network
   - policy network：预测每个落子位置的概率
   - value network：预测当前局面的胜率

4. 蒙特卡洛预演

   - 就是将原来穷举所有的可能性改为随机采样
   - policy network 能降低搜索宽度（只要把可能性高的位置采样出来，剪枝）
   - value network 能降低搜索深度（只要把当前局面的高的胜率采样出来，剪枝）

5. Alpha Go 的训练过程（不用记忆）

   - 通过人类棋谱进行预训练（分类预训练）
   - 通过自我对弈进行强化学习，生成 policy 网络
   - 通过自我对弈进行强化学习，生成 value 网络

6. 蒙特卡洛搜索（具体如何下棋）

   - 通过 policy network 选择落子位置
   - 通过 value network 评估当前局面的胜率
   - 通过蒙特卡洛预演进行搜索
   - selection（选择）：根据 policy network 选择落子位置
   - expansion（扩展）：在当前局面下扩展可能的落子位置
   - evaluation（评估）：通过 value network 评估当前局面的胜率
   - rollout（预演）：从当前局面开始，随机模拟对局直到结束
   - backup（回溯）：根据预演结果更新当前局面的胜率

7. 强化学习也可以用作文本上

   - MLE 训练的缺陷：Generic response（通用安全的回复），Repetition（重复）
   - 强化学习的目标：最大化奖励（BLEU, ROUGE, DISTINCT，meaningfulness, human likeness 等作为奖励函数）
   - 也有对应的 4 个内容需要进行设置：state、action、reward、policy
   - state：前一层的 encoder 的隐藏状态
   - action：即将生成的 token
   - reward：根据生成的文本进行评估（如 BLEU、ROUGE 等）
   - policy：通过一个神经网络来进行预测、即通过一个神经网络来进行预测执行 action 的概率
   - 可以有多种 reward、比如 Ease of answering（回答的容易程度）、 Information Flow（信息流动性）、Fluency（流畅度）、Relevance（相关性）等
   - Training RL-NLG：乘以一个 R 就可以了

8. RLHF（Reinforcement Learning from Human Feedback）

   - RLHF 是一种从人类反馈中进行强化学习的方法。它通过收集人类对模型输出的反馈来优化模型，从而实现更高质量的生成。RLHF 的核心思想是通过人类反馈来优化模型，从而实现更高质量的生成。

## 6.3 Optimization

1. 优化：即是通过调整模型参数 θ 来最小化损失函数 L ，从而提高模型的性能

2. 挑战：

   - Loss Landscape（损失函数的形状）：损失函数的形状可能非常复杂，包含多个局部最小值和鞍点
   - Saddle Points（鞍点）：鞍点是指在某个方向上是最小值，而在另一个方向上是最大值的点
   - Local Minima（局部最优）：局部最小值是指在某个区域内的最小值，但不是全局最小值
   - Slow at plateau（在平坦区域上收敛很慢）：在平坦区域上，梯度接近于零，导致收敛速度非常慢
   - vanishing gradient（梯度消失）：在深层网络中，梯度可能会逐渐消失，导致无法更新参数（比如在双曲函数 tanh 中，当输入值过大或过小时，梯度接近于零，更新就很慢）
   - 所以需要不同的学习模式

3. Batch Gradient Descent

   - 批量梯度下降：使用整个训练集来计算梯度，然后更新迭代
   - 优点：收敛稳定，适用于小规模数据集（自己用的）
   - 缺点：计算开销大，内存消耗高，收敛速度慢
   - 离线学习

4. Stochastic Gradient Descent (SGD)

   - 随机梯度下降：每次使用一个样本来计算梯度，然后更新迭代
   - 优点：计算开销小，内存消耗低，收敛速度快
   - 缺点：收敛不稳定，可能会陷入局部最小值
   - 在线学习

5. Mini-batch Gradient Descent

   - 小批量梯度下降：每次使用一小部分样本来计算梯度，然后更新迭代
   - 优点：平衡了批量梯度下降和随机梯度下降的优缺点，收敛速度快，内存消耗低
   - 缺点：需要选择合适的批量大小（batch size）

6. 学习率

   - 过小的学习率：收敛速度慢，可能会陷入局部最小值
   - 过大的学习率：可能会导致梯度震荡，甚至发散

7. SGD learning Rate

   - 策略：开始的时候学习率大一点，就可以快速收敛、然后逐渐减小学习率
   - 但是最终减小学习率之后、会收敛地很慢

8. SGD with Momentum

   - 动量：在更新参数时考虑之前的梯度，增加惯性
   - 公式：$v_t = \beta v_{t-1} + (1 - \beta) \nabla L(\theta_t)$
   - 优点：加速收敛，减少震荡
   - 缺点：需要选择合适的动量系数 β

9. Adaptive Learning Rate Methods

   - 自适应学习率方法：根据梯度的历史信息来调整学习率
   - 优点：自动调整学习率，适应不同的参数更新速度
   - 缺点：需要选择合适的超参数

10. Adagrad

    - Adagrad：根据参数的历史梯度均方和来调整学习率
    - 公式：$v_t = v_{t-1} + \nabla L(\theta_t)^2$
    - 优点：适应性强，适用于稀疏数据（对极小值极大值的个别参数都能适应弥补）
    - 缺点：学习率会逐渐减小，可能导致收敛过慢，一开始的学习率需要人为根据经验设定

11. RMSprop

    - RMSprop：对 Adagrad 进行改进，使用指数衰减平均来计算梯度的均方和
    - 公式：$v_t = \beta v_{t-1} + (1 - \beta) \nabla L(\theta_t)^2$
    - 优点：解决了 Adagrad 学习率过快减小的问题，适用于非平稳目标
    - 缺点：需要选择合适的超参数 β

12. Adadelta

    - Adadelta：对 RMSprop 进行改进，使用指数衰减平均来计算梯度的均方和，并且不需要手动设置学习率
    - 公式：$v_t = \beta v_{t-1} + (1 - \beta) \nabla L(\theta_t)^2$
    - 优点：不需要手动设置学习率，适用于非平稳目标
    - 缺点：需要选择合适的超参数 β

13. Adam （Adaptive Moment Estimation）

    - RMSProp + Momentum：结合了 RMSprop 和 Momentum 的优点，使用一阶矩和二阶矩的指数衰减平均来计算梯度
    - Adam：结合了 Adagrad 和 RMSprop 的优点，使用一阶矩和二阶矩的指数衰减平均来计算梯度
    - 公式：$m_t = \beta_1 m_{t-1} + (1 - \beta_1) \nabla L(\theta_t)$，$v_t = \beta_2 v_{t-1} + (1 - \beta_2) \nabla L(\theta_t)^2$
    - 优点：适用于大规模数据和高维参数，收敛速度快
    - Low memory footprint（低内存占用）：只需要存储一阶矩和二阶矩的平均值
    - Universal applicability（通用适用性）：适用于各种类型的神经网络和任务
    - Automatic bias correction for initialization effects

14. 总结

    - 如果数据是稀疏的，就用自适用方法，即 Adagrad, Adadelta, RMSprop, Adam。
    - RMSprop, Adadelta, Adam 在很多情况下的效果是相似的。
    - Adam 就是在 RMSprop 的基础上加了 bias-correction 和 momentum，
    - 随着梯度变的稀疏，Adam 比 RMSprop 效果会好。
    - 整体来讲，Adam 是最好的选择。

## 6.6 复习课 & 考试知识点

1. 设计题答题思路：

   - 把思路和关键要素都答出来（输入、输出、模型、损失函数、优化方法等）
   - 不用过细、比如参数怎么调之类
   - 强化学习的题目参考四要素来回答（state、action、reward、policy）

2. 机器学习的四要素

   - 数据：输入数据和标签
   - 模型：选择合适的模型来拟合数据
   - 损失函数：定义模型的损失函数来衡量模型的性能
   - 优化方法：选择合适的优化方法来更新模型参数

3. 过拟合

   - 过拟合：模型在训练集上表现很好，但在测试集上表现不好
   - 解决方法：增加数据量、使用正则化、使用交叉验证等

4. 决策树

   - 按照数据的特征进行划分，直到满足停止条件
   - 决策树：一种基于树结构的分类和回归模型（信息熵）
   - 通过选择最优特征来划分数据集

5. 朴素贝叶斯

   - 朴素贝叶斯：一种基于贝叶斯定理的分类模型，假设特征之间相互独立
   - 通过计算每个类别的后验概率来进行分类
   - 假设：
     - 特征之间相互独立
     - 类别之间的先验概率已知

6. K-Nearest Neighbors (KNN)

   - KNN：一种基于实例的分类和回归模型，通过计算样本之间的距离来进行分类
   - 通过选择最近的 K 个邻居来进行分类或回归
   - 距离度量：欧氏距离、曼哈顿距离等
   - 关注决策边界：k 的大小和决策边界的关系：
     - k 较小：决策边界复杂，容易过拟合
     - k 较大：决策边界平滑，可能欠拟合
   - 关注 k 如何选择：
     - 通过交叉验证来选择合适的 k 值
     - 一般选择奇数，避免平局

7. Linear Discriminant Funcions

   - 判别式分类器
   - 线性判别函数：通过线性组合特征来进行分类
   - 通过最大化类间距离和最小化类内距离来进行分类
   - 适用于线性可分的数据

8. Logistic Regression （重点内容）

   - 逻辑回归：一种基于逻辑函数的分类模型，通过最大化似然函数来进行分类
   - 通过 sigmoid 函数将线性组合的结果映射到 [0, 1] 区间
   - 适用于二分类问题
   - 关注交叉熵是怎么推导出来的（输入的是一个向量、得到的是一个概率，概率和标签（0 或者 1）不是对应的）

9. Softmax Regression

   - 算指数
   - Softmax 回归：一种多分类模型，通过 softmax 函数将线性组合的结果映射到 [0, 1] 区间
   - 通过最大化似然函数来进行分类
   - 适用于多分类问题
   - 关注 softmax 函数的定义和推导过程（输入的是一个向量、得到的是一个概率分布）
   - 输入的是一个向量，输出的是一个概率分布

10. Support Vector Machines (SVM)

    - 根据边界的大小进行推导出来
    - 支持向量机：一种基于最大间隔的分类模型，通过寻找最优超平面来进行分类
    - 通过最大化类间距离来进行分类
    - 适用于线性可分和非线性可分的数据（通过核函数）
    - 关注 SVM 的原理和核函数的作用

11. Perceptron

    - 感知机：一种基于线性分类的模型，通过迭代更新权重来进行分类
    - 通过梯度下降法来更新权重
    - 适用于线性可分的数据
    - 不能解决 xor 问题

12. Multi-layer Perceptron (MLP)

    - 多层感知机：一种基于多层神经网络的分类和回归模型，通过前向传播和反向传播来进行训练
    - 通过激活函数（如 ReLU、sigmoid 等）来引入非线性
    - 适用于非线性可分的数据
    - 关注反向传播的训练过程（前向过程和反向过程）

13. 深度学习的思考

    - 模块化：提取不同的特征模块
    - 可扩展性：可以通过增加层数和节点数来提高模型的表达能力

14. 深度学习相较于传统机器学习的优势

    - 表达能力：深度学习模型可以自动提取特征并可进行训练，具有更强的表达能力
    - 端到端训练：深度学习模型可以通过端到端的方式进行训练，无需手动设计特征
    - 适应性：深度学习模型可以适应不同类型的数据和任务

15. 语言模型

    - 语言模型：通过学习语言的统计特性来进行文本生成和理解
    - 通过概率分布来建模语言的结构和语义
    - （考试重点）Word Embedding：将词语映射到向量空间中，捕捉词语之间的语义关系

16. Word2Vec

    - Word2Vec：一种基于神经网络的词向量表示方法，通过上下文窗口来学习词语的向量表示
    - CBOW（Continuous Bag of Words）：通过上下文词语来预测中心词

17. 语言模型

    - 语言模型：通过学习语言的统计特性来进行文本生成和理解
    - 通过概率分布来建模语言的结构和语义
    - RNN（Recurrent Neural Network）：通过循环神经网络来建模序列数据，适用于处理时间序列和文本数据
    - 没有 attention 的时候、会有瓶颈、导致细节的丢失

18. Attention Mechanism

    - 注意力机制：通过加权平均来关注输入序列中的重要部分，解决了 RNN 的瓶颈问题
    - 通过计算注意力权重来加权输入序列中的每个元素
    - 适用于处理长序列数据和文本数据

19. Self-Attention

    - 自注意力机制：通过计算输入序列中每个元素之间的关系来加权输入序列中的每个元素
    - 通过计算 Query、Key 和 Value 来实现自注意力机制
    - 适用于处理长序列数据和文本数据

20. Transformer

    - Transformer：一种基于自注意力机制的序列到序列模型，通过编码器和解码器来进行文本生成和理解
    - 编码器：通过自注意力机制和前馈神经网络来编码输入序列
    - 解码器：通过自注意力机制、编码器-解码器注意力机制和前馈神经网络来解码输出序列
    - 适用于处理长序列数据和文本数据

21. Pre-trained Language Models

    - 预训练语言模型：通过大规模语料库进行预训练，然后在特定任务上进行微调
    - BERT（Bidirectional Encoder Representations from Transformers）：一种双向编码器表示模型，通过 Masked Language Model 和 Next Sentence Prediction 进行预训练 （用于压缩文本、进行文本理解）
    - GPT（Generative Pre-trained Transformer）：一种生成式预训练模型，通过自回归语言模型进行预训练

22. CNN

    - 每个 MLP 只关注局部的特征
    - 卷积神经网络：通过卷积层、池化层和全连接层来进行图像分类和目标检测
    - 卷积层：通过卷积核对输入图像进行特征提取
    - 池化层：通过下采样来减少特征图的尺寸
    - 全连接层：通过全连接层将特征图转换为分类结果

23. 语义分割

    - down-sampling：通过池化层来减少特征图的尺寸
    - up-sampling：通过上采样层来恢复特征图的尺寸
    - 通过 transposed convolution（反卷积）来进行上采样
    - 语义分割：将图像中的每个像素分配到一个类别
    - U-Net：一种用于医学图像分割的卷积神经网络，通过编码器和解码器来进行图像分割
    - FCN（Fully Convolutional Network）：一种全卷积网络，通过卷积层和上采样层来进行图像分割

24. Fast R-CNN （关注思路）

    - Fast R-CNN：一种用于目标检测的卷积神经网络，通过区域提议网络（RPN）来生成候选区域，然后对每个候选区域进行分类和回归
    - 通过 RoI Pooling 来将不同尺寸的候选区域转换为固定尺寸的特征图
    - 通过 Softmax 分类器和边界框回归器来进行目标检测

25. 无监督学习

    - 无监督学习：通过数据本身来进行训练，无需标签
    - 聚类：将数据分为不同的簇，常用的算法有 K-means、DBSCAN 等
    - 降维：将高维数据映射到低维空间，常用的算法有 PCA、t-SNE 等
    - 自编码器：通过编码器和解码器来进行数据压缩和重建
    - GAN（生成对抗网络）：通过生成器和判别器来进行数据生成和对抗训练

26. K-means

    - K-means：一种基于距离的聚类算法，通过迭代更新簇中心来进行聚类
    - 通过计算每个样本到簇中心的距离来分配样本到簇
    - 通过更新簇中心来优化聚类结果
    - 需要选择合适的 K 值
    - 要看一看 k 怎么选取和算法的主要过程（计算）

27. PCA（主成分分析）

    - 找到数据变化最快的维度
    - PCA：一种基于线性变换的降维算法，通过寻找数据的主成分来进行降维
    - 通过计算协方差矩阵和特征值分解来找到主成分
    - 通过选择前 k 个主成分来进行降维
    - 适用于线性可分的数据

28. 自编码器

    - 降维模型，但是和后续的 diffusion model 有关系
    - 自编码器：一种无监督学习模型，通过编码器和解码器来进行数据压缩和重建
    - 编码器：将输入数据映射到潜在空间
    - 解码器：将潜在空间的表示映射回原始数据空间
    - 通过最小化重建误差来训练自编码器
    - 适用于数据压缩和特征学习

29. 生成式模型（概念考察为主）

    - 模仿概率分布（概率分布转换器）
    - 生成式模型：通过学习数据的分布来生成新的样本
    - GAN（生成对抗网络）：通过生成器和判别器来进行数据生成和对抗训练
    - VAE（变分自编码器）：通过变分推断来学习数据的潜在表示
    - Diffusion Model：通过逐步去噪声的过程来生成新的样本
    - 适用于图像生成、图像修复、图像超分辨率等任务

30. GAN

    - 生成对抗网络：通过生成器和判别器来进行数据生成和对抗训练
    - 生成器：生成新的样本
    - 判别器：判断样本是真实的还是生成的
    - 通过对抗训练来优化生成器和判别器
    - 目标函数：最小化生成器的损失函数和最大化判别器的损失函数
    - 损失函数：交叉熵损失函数
    - 应用：图像生成、图像修复、图像超分辨率

31. 强化学习

    - 强化学习：通过与环境的交互来优化决策策略，从而最大化累积奖励
    - 马尔可夫决策过程（MDP）：描述强化学习中的决策过程，包括状态空间、动作空间、转移概率和奖励函数
    - Q-learning：一种无模型的强化学习算法，通过学习状态-动作值函数来优化决策策略
    - DQN（深度 Q 网络）：结合了 Q-learning 和深度学习的优点，通过深度神经网络来近似 Q 值函数
    - 策略梯度方法：直接学习策略函数，通过计算策略函数的梯度来优化策略
    - 应用：游戏、机器人控制、自动驾驶等
